{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Linear Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression\n",
    "\n",
    "1. 放射变换（affline transformation）。线性回归假设的模型是输入特征的一个仿射变换。仿射变换的特点是通过加权和对特征的进行线性变化，并通过偏置项来进行平移得到的。\n",
    "2. 通常用$\\hat{y}$来表示估计值。\n",
    "3. 虽然我们相信给定$\\boldsymbol{x}$预测的最佳模型会是线性的， 但我们很难找到一个有个$n$样本的真实数据集，其中对于所有的$1\\leqslant i \\leqslant y$, $y^{(i)}$完全等于$\\boldsymbol{w}^T\\boldsymbol{x}^{(i)}+\\boldsymbol{b}$。无论我们使用什么手段来观察特征$\\boldsymbol{X}$和标签$\\boldsymbol{y}$，**都可能会出现少量的观测误差**。因此，即使确信特征与标签的潜在关系是线性的，我们也会加入一个噪声项来考虑观测误差带来的影响。\n",
    "4. 由于平方误差函数中的二次方项，估计值$\\hat{y}^{(i)}$和观测值$y^{(i)}$之间较大的差异将导致更大的损失。为了度量模型在整个数据集上的质量，我们需计算在训练集个样本上的损失均值（也等价于求和）。\n",
    "    $$L(\\boldsymbol{w}, \\boldsymbol{b})=\\frac{1}{n}\\sum\\limits_{i=1}^n l^{(i)}(\\boldsymbol{w},\\boldsymbol{b})=\\frac{1}{n}\\sum\\limits_{i=1}^n \\frac{1}{2} (\\boldsymbol{w}^{T}\\boldsymbol{x}^{(i)}+\\boldsymbol{b}-\\boldsymbol{y}^{(i)})^2 \\tag{3.1.6}$$\n",
    "    在训练模型时，我们希望寻找一组参数$(\\boldsymbol{w}^*, \\boldsymbol{b}^*)$，这组参数能最小化在所有训练样本上的总损失。如下式：$\\boldsymbol{w}^*, \\boldsymbol{b}^* =\\underset{\\boldsymbol{w},\\boldsymbol{b}}{argmin}L(\\boldsymbol{w},\\boldsymbol{b})$。\n",
    "5. 解析解：$\\boldsymbol{w}^* =(\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T \\boldsymbol{y}$。像线性回归这样的简单问题存在解析解，但并不是所有的问题都存在解析解。**解析解可以进行很好的数学分析，但解析解对问题的限制很严格**（这个限制条件在于），导致它无法广泛应用在深度学习里。[解答参考文字](https://zhuanlan.zhihu.com/p/74157986)。[解答参考视频](https://www.bilibili.com/video/BV1ro4y1k7YA?spm_id_from=333.337.search-card.all.click)。\n",
    "   1. 这里如何得来的？证明如下。\n",
    "   2. 为什么还有$\\boldsymbol{X}^T$这一项？答：这是为了表示他们之间的距离（L2范数）。**两个形状相同向量之间的距离可以表示为一个向量的转置乘以另外一个向量**。推导过程如下：\n",
    "\n",
    "        $$\n",
    "        \\begin{equation}\n",
    "        \\begin{aligned}\n",
    "        \\text{Known:} & \\text{the sample space is}\\{(x_1,y_1),(x_2,y_2),\\cdots (x_n,y_n)\\}\\\\\n",
    "         & \\text{equation: }\\boldsymbol{Y}=\\boldsymbol{X}\\boldsymbol{B}\\\\\n",
    "         & \\boldsymbol{Y}=\\begin{pmatrix}\n",
    "            y_1 \\\\\n",
    "            y_2 \\\\\n",
    "            \\vdots \\\\\n",
    "            y_n\n",
    "            \\end{pmatrix};\n",
    "        \\boldsymbol{X}=\\begin{bmatrix}\n",
    "            1 & x_1 \\\\\n",
    "            1 & x_2 \\\\\n",
    "            & \\vdots \\\\\n",
    "            1 & x_n\n",
    "            \\end{bmatrix};\n",
    "        \\boldsymbol{B}=\\begin{pmatrix}\n",
    "            \\alpha \\\\\n",
    "            \\beta\n",
    "            \\end{pmatrix}.\\\\\n",
    "         & \\alpha\\text{ is intercept,} \\beta \\text{ is slope.} \\\\\n",
    "         & \\therefore \\boldsymbol{Y} = \\boldsymbol{X}\\boldsymbol{B} + \\boldsymbol{\\gamma} \\\\\n",
    "         & \\boldsymbol{\\gamma} =\\begin{pmatrix}\n",
    "            \\epsilon_1 \\\\\n",
    "            \\epsilon_2 \\\\\n",
    "            \\vdots \\\\\n",
    "            \\epsilon_n\n",
    "            \\end{pmatrix};\\\\\n",
    "\n",
    "        \\text{Target is: } & \\boldsymbol{w}^*, \\boldsymbol{b}^* =\\underset{\\boldsymbol{w},\\boldsymbol{b}}{argmin}L(\\boldsymbol{w},\\boldsymbol{b})\\\\\n",
    "        \\text{solution: } & \\\\\n",
    "         & \\boldsymbol{X}\\boldsymbol{B} - \\vec{\\boldsymbol{y}} = \\begin{bmatrix}\n",
    "            \\vec{x}_1^T b \\\\\n",
    "            \\vec{x}_2^T b \\\\\n",
    "            \\vdots \\\\\n",
    "            \\vec{x}_n^T b\n",
    "            \\end{bmatrix} - \\begin{bmatrix}\n",
    "            \\vec{y}_1 \\\\\n",
    "            \\vec{y}_2 \\\\\n",
    "            \\vdots \\\\\n",
    "            \\vec{y}_n\n",
    "        \\end{bmatrix}\\\\\n",
    "        & = \\begin{bmatrix}\n",
    "            \\vec{x}_1^T b - \\vec{y}_1\\\\\n",
    "            \\vec{x}_2^T b - \\vec{y}_2\\\\\n",
    "            \\vdots \\\\\n",
    "            \\vec{x}_n^T b - \\vec{y}_n\n",
    "        \\end{bmatrix}\\\\\n",
    "         & \\because \\vec{z}^T\\vec{z} = \\sum_i z_i^2;\\\\\n",
    "         & \\therefore \\begin{bmatrix}\n",
    "            \\vec{x}_1^T b - \\vec{y}_1\\\\\n",
    "            \\vec{x}_2^T b - \\vec{y}_2\\\\\n",
    "            \\vdots \\\\\n",
    "            \\vec{x}_n^T b - \\vec{y}_n\n",
    "            \\end{bmatrix} \\\\\n",
    "         & = \\frac{1}{2} (\\boldsymbol{X}\\boldsymbol{B} - \\vec{\\boldsymbol{y}})^T (\\boldsymbol{X}\\boldsymbol{B} - \\vec{\\boldsymbol{y}}) = \\frac{1}{2} \\sum\\limits_{i=1}^n(\\vec{x}_i^T b - \\vec{y}_i)\\\\\n",
    "         & =L(\\boldsymbol{B})\\\\\n",
    "         & \\nabla_B L(\\boldsymbol{B}) = \\nabla_B \\frac{1}{2} (\\boldsymbol{X}\\boldsymbol{B} - \\vec{\\boldsymbol{y}})^T (\\boldsymbol{X}\\boldsymbol{B} - \\vec{\\boldsymbol{y}}) \\\\\n",
    "         & = \\frac{1}{2} \\nabla_B ((\\boldsymbol{X}\\boldsymbol{B})^T \\boldsymbol{X}\\boldsymbol{B} - (\\boldsymbol{X}\\boldsymbol{B})^T \\vec{y} - \\vec{y}^T(\\boldsymbol{X}\\boldsymbol{B}) + \\vec{y}^T \\vec{y}) \\\\\n",
    "         & \\because \\vec{a}^T\\vec{b} = \\vec{b}^T\\vec{a} \\;\\text{ and }\\;\\vec{y}^T \\vec{y}\\text{ is independent of }\\boldsymbol{B}.\\\\\n",
    "         & \\because \\nabla_x \\vec{b}^T x =  \\vec{b}\\;\\text{ and }\\;\\nabla_x \\vec{x}^T \\boldsymbol{A}x =  2\\boldsymbol{A}\\vec{x}\\;\\text{ for symmetric matrix.}\\\\\n",
    "         & \\therefore = \\frac{1}{2} \\nabla_B (\\boldsymbol{B}^T (\\boldsymbol{X}^T \\boldsymbol{X})\\boldsymbol{B} - (\\boldsymbol{X}\\boldsymbol{B})^T \\vec{y} - \\vec{y}^T(\\boldsymbol{X}\\boldsymbol{B})) \\\\\n",
    "         & = \\frac{1}{2} \\nabla_B (\\boldsymbol{B}^T (\\boldsymbol{X}^T \\boldsymbol{X})\\boldsymbol{B} - \\vec{y}^T(\\boldsymbol{X}\\boldsymbol{B})  - \\vec{y}^T(\\boldsymbol{X}\\boldsymbol{B})) \\\\\n",
    "         & = \\frac{1}{2}(2(\\boldsymbol{X}^T \\boldsymbol{X})\\boldsymbol{B}-2\\vec{y}^T \\boldsymbol{X})\\\\\n",
    "         & = (\\boldsymbol{X}^T \\boldsymbol{X})\\boldsymbol{B}-\\vec{y}^T \\boldsymbol{X}\\\\\n",
    "         & \\text{To minimize L, L is convex function, we set its derivatives to zero, and obtain the normal equations:}\\\\\n",
    "         & (\\boldsymbol{X}^T \\boldsymbol{X})\\boldsymbol{B} = \\vec{y}^T\\boldsymbol{X} = \\boldsymbol{X}^T\\vec{y}\\\\\n",
    "         & \\Rightarrow \\boldsymbol{B} = (\\boldsymbol{X}^T \\boldsymbol{X})^{-1}\\boldsymbol{X}^T \\vec{y} \\\\\n",
    "         & \\text{Proof complete.}\n",
    "        \\end{aligned}\n",
    "        \\end{equation}\n",
    "        $$\n",
    "\n",
    "6. 随机梯度下降。梯度下降（gradient descent）的方法，这种方法**几乎可以优化所有深度学习模型**。它通过不断地在损失函数递减的方向上更新参数来降低误差。但实际中的执行可能会非常慢：**因为在每一次更新参数之前，我们必须遍历整个数据集**。 因此，我们通常会在每次需要计算更新的时候**随机抽取一小批样本**，这种变体叫做小批量随机梯度下降（minibatch stochastic gradient descent）。\n",
    "   1. **即使我们的函数确实是线性的且无噪声，这些估计值也不会使损失函数真正地达到最小值。因为算法会使得损失向最小值缓慢收敛，但却不能在有限的步数内非常精确地达到最小值**。\n",
    "   2. 线性回归恰好是一个在整个域中只有一个最小值的学习问题。但是对于像深度神经网络这样复杂的模型来说，损失平面上通常包含多个最小值。深度学习实践者很少会去花费大力气寻找这样一组参数，使得在训练集上的损失达到最小。事实上，**更难做到的是找到一组参数，这组参数能够在我们从未见过的数据上实现较低的损失**，这一挑战被称为泛化（generalization）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CommonCode import Timer\n",
    "import numpy \n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矢量化加速\n",
    "\n",
    "f'{timer.stop():.5f} sec' [python 3.6之后字符串格式化用法参考说明](https://geek-docs.com/python/python-tutorial/python-fstring.html#Python_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 使用for循环所消耗的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(10000,) dtype=float32, numpy=array([2., 2., 2., ..., 2., 2., 2.], dtype=float32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'7.23041 sec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "a = tf.ones(n)\n",
    "b = tf.ones(n)\n",
    "\n",
    "c = tf.Variable(tf.zeros(n))\n",
    "timer = Timer()\n",
    "for i in range(n):\n",
    "    c[i].assign(a[i] + b[i])\n",
    "print(c)\n",
    "f'{timer.stop():.5f} sec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 使用矢量化之后消耗的时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000 sec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d = a + b\n",
    "f'{timer.stop():.5f} sec'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normal distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(x, mu, sigma):\n",
    "    p = 1 / math.sqrt(2 * math.pi * sigma**2)\n",
    "    return p * np.exp(-0.5 / sigma**2 * (x - mu)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "均方误差损失函数（简称均方损失）可以用于线性回归的一个原因是：我们假设了观测中包含噪声，其中噪声服从正态分布。\\\n",
    "也就是说：**使用什么损失函数需要考虑噪声的分布情况**。\\\n",
    "\n",
    "最大似然估计（maximum likelihood estimation）的[详细说明详见](../../mathematics/ProbabilityTheory.md)中关于maximum likelihood estimation的说明。\\\n",
    "\n",
    "在3.1.3中说明了服从正态分布的噪声，最小化均方误差等价于对线性模型的极大似然估计。这个中间“可以写出通过给定的x观测到特定y的似然”的这句没有理解?????? \\\n",
    "\n",
    "对于线性回归，每个输入都与每个输出（在本例中只有一个输出）相连，我们将这种变换称为全连接层（fully-connected layer）或称为稠密层（dense layer）。这里定义了全连接层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最大似然估计 Maximum Likilihood Estimation\n",
    "\n",
    "1. 一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。最大似然估计就是在估计模型的参数。也就是说**最大似然估计是已知模型和样本，来估计模型的参数**。\n",
    "2. 参考\n",
    "   1. 文字参考\n",
    "      1. [直接的说明](https://zhuanlan.zhihu.com/p/26614750)\n",
    "      2. [比较了概率和统计的区别，同时也说了最大似然估计的概念](https://blog.csdn.net/u011508640/article/details/72815981)。\n",
    "   2. 视频讲解的例子参考<https://www.bilibili.com/video/BV1Hb4y1m7rE?spm_id_from=333.337.search-card.all.click>。\n",
    "\n",
    "3. 离散值的例子：\n",
    "\n",
    "   设一个袋子里有非常多的小球（样本数量：非常大。也就忽略的放回抽样和不放回抽样），**极大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的**。其中有两种样本，一种是白球，定义为样本1；一种是红球，定义为样本2。两种样本数量的比值如下表所示，其中$\\theta$是未知的：\n",
    "\n",
    "   |X|样本1|样本2|\n",
    "   |---|---|---|\n",
    "   |P|$\\theta$|$1-\\theta$|\n",
    "\n",
    "   如何判断袋子中小球的分布呢？自然就想到的抽样的方式来对袋子中的小球的分布进行判断。现在假设从袋子中按照顺序抽出了5个小球，分别是1、1、2、1、2。那么它们的抽样情况如下表所示：\n",
    "\n",
    "   |抽样结构（按顺序）|1|1|2|1|2|\n",
    "   |---|---|---|---|---|---|\n",
    "   |抽出该样本的概率|$\\theta$|$\\theta$|$1-\\theta$|$\\theta$|$1-\\theta$|\n",
    "\n",
    "   抽出这个顺序样本的概率为$L(\\theta)=\\theta\\theta (1-\\theta)\\theta(1-\\theta)=\\theta^3(1-\\theta)^2$，定义$L(\\theta)$为似然函数。抽出这组样本的概率显然是会随着$\\theta$的变化而变化。随着$\\theta$的变化$L(\\theta)$有无数种值，然后按照“存在即合理”的思想，直接认为应该让$L(\\theta)$最大的$\\theta$为被选择的分布（实际上这个地方还是没有理解清楚其中的逻辑，但是先这样使用）。<https://zhuanlan.zhihu.com/p/26614750>中给出的说明是一个反问句式：“那么既然事情已经发生了，为什么不让这个出现的结果的可能性最大呢？这也就是最大似然估计的核心”。\\\n",
    "\n",
    "   这里进行说明为什么需要求最大。在视频<https://www.bilibili.com/video/BV1Y64y1Q7hi?spm_id_from=333.337.search-card.all.click>中的8:30开始说明这个问题。\n",
    "\n",
    "   描述性的说明，这个描述对于理解非常重要：\n",
    "   1. 在抛硬币的例子中，每次抛硬币事件的分布如下：\n",
    "      |X|正面|反面|\n",
    "      |---|---|---|\n",
    "      |P|$\\theta$|$1-\\theta$|\n",
    "   2. 如果抛了10次，得到的10次结果为：7次正面，3次反面。\n",
    "   3. 因为只有2个样本，我们猜测模型是二项分布也就是(0-1)分布模型。这个时候就希望能将$\\theta$的值估计出来。\n",
    "   4. 这里需要强调的一点：\n",
    "      一种分布A如下：\n",
    "\n",
    "      |X|正面|反面|\n",
    "      |---|---|---|\n",
    "      |P|0.1|0.9|\n",
    "\n",
    "      一种分布B如下：\n",
    "\n",
    "      |X|正面|反面|\n",
    "      |---|---|---|\n",
    "      |P|0.7|0.3|\n",
    "\n",
    "      一种分布C如下：\n",
    "\n",
    "      |X|正面|反面|\n",
    "      |---|---|---|\n",
    "      |P|0.8|0.2|\n",
    "\n",
    "      在实际抛的过程中都是有可能出现7次正面，3次反面的情况的。只不过它们出现这种情况的概率不同而已。这个过程就是在某种模型的情况下求某次事件的条件概率。\n",
    "   5. 这个时候就需要通过已知的抽样结果：7次正面，3次反面。**来估计具有最大似然（这里表述为似然，而不是概率了。因为是从统计结果分析模型参数了。这里可以理解为可能性最大的结果。同样一个过程从模型到结果称为概率，从结果到模型称为似然）出现这种抽样结果的分布是什么样的**。这就是为什么叫**最大**似然估计的原因。\n",
    "   6. 最后的结果我们就直接认为是符合上述抽样结果的分布！注意，不能认为最大似然估计得出的模型参数就是真实的参数。因为模型对应的真实参数是没有办法确定的。只能估计其可能性最大值。当知道某种模型产生的结果然后去反推概率模型时，往往就会用到最大似然估计。这也是机器学习最重要的理论基础之一。\n",
    "\n",
    "   前提，MLP可以通过添加更多的层数来拟合任意概率模型的曲线。\n",
    "   推导过程如下：\n",
    "\n",
    "   $$\n",
    "   \\begin{equation}\n",
    "   \\begin{aligned}\n",
    "   & C_i\\text{表示的是事件，}\\theta\\text{表示的是概率模型的参数，这里代指概率模型。}\\\\\n",
    "   & P(C_1,C_2, \\cdots, C_n |\\theta)\\\\\n",
    "   & y_i\\text{表示的是标签，}\\hat{y}_i\\text{表示的是预测值，}\\boldsymbol{W}, \\boldsymbol{b}\\text{表示的是MLP的参数，这里代指神经网络模型。}\\\\\n",
    "   & P(y_1,y_2, \\cdots, y_n |\\boldsymbol{W}, \\boldsymbol{b})\\\\\n",
    "   & = \\prod \\limits_{i=1}^n P(y_i|\\boldsymbol{W}, \\boldsymbol{b})\\\\\n",
    "   & P(y_i|\\boldsymbol{W}, \\boldsymbol{b})\\text{表示在神经网络模型下，和标签对应的结果的概率分别是多少。当这个似然值最大的时候，就可以认定该模型和真实数据对应的模型是最接近的（甚至“武断”的认为就是一样的）。}\\\\\n",
    "   & = \\prod \\limits_{i=1}^n P(y_i|\\hat{y}_i)\\\\\n",
    "   & \\text{如果是一个二分类模型，那么就多次的二项分布（也就是0-1分布），也就是符合伯努利分布。}\\\\\n",
    "   & \\because \\text{伯努利分布为：} x_i \\in \\{0, 1\\};\n",
    "      f(x)=p^x (1-p)^x = \\begin{matrix}\n",
    "      & p, x=1 \\\\\n",
    "      & 1-p, x=0\n",
    "      \\end{matrix}\\\\\n",
    "   & \\therefore \\prod \\limits_{i=1}^n P(y_i|\\hat{y}_i) = \\prod \\limits_{i=1}^n \\hat{y}_i^{y_i}(1-\\hat{y}_i)^{1-y_i} \\\\\n",
    "   & \\text{对等式求对数。}\\\\\n",
    "   & \\log(\\prod \\limits_{i=1}^n \\hat{y}_i^{y_i}(1-\\hat{y}_i)^{1-y_i})\\\\\n",
    "   & = \\sum\\limits_{i=1}^n \\log(\\hat{y}_i^{y_i}(1-\\hat{y}_i)^{1-y_i})\\\\\n",
    "   & = \\sum\\limits_{i=1}^n (y_i\\log(\\hat{y}_i) + (1-y_i)\\dot\\log(1-\\hat{y}_i))\\\\\n",
    "   & \\text{目的是求上式的最大值：}max(\\sum\\limits_{i=1}^n (y_i\\log(\\hat{y}_i) + (1-y_i)\\dot\\log(1-\\hat{y}_i)))\\\\\n",
    "   & \\text{一般习惯求最小值，所以上式变为：}min-(\\sum\\limits_{i=1}^n (y_i\\log(\\hat{y}_i) + (1-y_i)\\dot\\log(1-\\hat{y}_i)))\\\\\n",
    "   & \\text{Completed.}\n",
    "   \\end{aligned}\n",
    "   \\end{equation}\n",
    "   $$\n",
    "\n",
    "   下面是求$L(\\theta)=\\theta^3(1-\\theta)^2$最大极值点的具体步骤：\n",
    "\n",
    "      1. 由于$\\theta^3(1-\\theta)^2$直接求导不好处理，所以先将公式两边同时求$\\ln$;\n",
    "      2. 等式两边同时求对数。对数函数有个性质，一方面可以将连乘转化为加减；另一方面对数函数不会改变原函数的单调性的(不会改变原函数中点的相对大小)，因为以e为底的对数函数是单增的。等式变为$\\ln L(\\theta) = \\ln (\\theta^3(1-\\theta)^2) = 3\\ln\\theta + 2 \\ln (1-\\theta)$\n",
    "      3. 对$\\theta$求导数。$\\frac{d\\ln L(\\theta)}{d\\theta} = \\frac{3}{\\theta} - \\frac{2}{1-\\theta}$\n",
    "      4. 求极值点，令$\\frac{d\\ln L(\\theta)}{d\\theta} = \\frac{3}{\\theta} - \\frac{2}{1-\\theta} = 0$。求得极值点为$\\hat{\\theta} = \\frac{3}{5}$。\n",
    "4. 连续值的例子：\n",
    "\n",
    "   $X \\sim U(0, a), \\; \\text{a is unknow.} \\\\ f(x)=\\begin{cases} \\frac{1}{a}, & \\text{if a} \\in (0,a) \\\\ 0, & \\text{if a is others} \\end{cases}$。抽取n个样本点，对应的事件分别是$\\{X_1,X_2,\\cdots,X_n\\}$，事件对应的样本点分别是$\\{x_1, x_2, \\cdots ,x_n\\}$，对应每个样本点的概率密度为$f(x_1), f(x_2), \\cdots ,f(x_n)$。那么$\\{X_1,X_2,\\cdots,X_n\\}$的联合概率密度（联合概率就是多个事件同时发生时的概率）为$L(a) =f(x_1)f(x_2)\\cdots f(x_n) = \\frac{1}{a}\\frac{1}{a}\\cdots \\frac{1}{a}=\\frac{1}{a^n}$。\n",
    "   这里需要注意，不能再使用离散值时的例子了。因为先取对数$\\ln L(a) = -n\\ln a$，然后再求导$\\frac{d\\ln L(a)}{da}=\\frac{-n}{a}$，然后令$\\frac{d\\ln L(a)}{da}=\\frac{-n}{a} = 0$的条件是$a \\rightarrow +\\infty$。这显然是不合适的。\\\n",
    "   所以这里采用了另外一种方法。为了使得$L(a)=\\frac{1}{a^n}$取得最大值，就需要a尽可能的小。此时也就需要分析a的取值范围。因为a是一组已经抽样出来的点，而且a是在$\\{x_1, x_2, \\cdots ,x_n\\}$中的一个值。$\\{x_1, x_2, \\cdots ,x_n\\}$是已经存在的抽样样本，也就是已经是事实了。所以a只能取$max\\{x_1, x_2, \\cdots ,x_n\\}$，这样就可以使得“已经是事实”的事件成立（如果取得值小于$x_n$，那么$x_n$是如何取得的呢？）。所以$\\hat{a}=max\\{x_1, x_2, \\cdots ,x_n\\}$。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 交叉熵\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.6 回答其中的问题。"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d94ea807e9dd88dec85d6135010093db08445b4f78f2386ac1d177de969ce657"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
