# 推荐系统

1. 参考书：《推荐系统实践》，作者：项亮

## 分类

1. 按应用场景分类
   1. 个性化推荐
   2. 相关推荐
   3. 热门推荐
2. 按使用技术分类
   1. 基于item的推荐
   2. 基于user的推荐（也就是基于用户好友关系的推荐）
   3. 基于协同过滤的推荐

## 1. 好的推荐系统

1. 推荐系统和搜索引擎是互补的关系。使用搜索引擎时，用户在知道准确的关键词。在用户无法提供关键词时，推荐系统通过通过分析用户的历史行为给用户的兴趣建模来满足用户的兴趣需求。
2. 推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐能够满足他们兴趣和需求的信息。
3. 从物品的角度出发，推荐系统可以更好地发掘物品的长尾（long tail）。
4. 推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式。
5. 推荐系统应用都是由前台的展示页面、后台的日志系统以及推荐算法系统3部分构成的。
6. 针对不同的推荐应用场景，推荐算法有很大的不同。比如音乐、电影、电子商务这三种物品本身的属性差别就非常大。其他的比如广告推荐、位置推荐等，应用场景的不同、需要推荐物品的不同对推荐算法的影响非常大。

### 评测标准

1. 括准确度、覆盖度、新颖度、惊喜度、信任度、透明度等。这**些指标中，有些可以离线计算，有些只有在线才能计算，有些只能通过用户问卷获得**。
2. 主要有3种评测推荐效果的实验方法，即离线实验（offline experiment）、用户调查（user study）和在线实验（online experiment）。
3. 离线实验的缺点：无法计算商业上关心的指标。离线实验的指标和商业指标存在差距。
4. 用户调查的优缺点也很明显。它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是**招募测试用户代价较大**，很难组织大规模的测试用户，因此会使测试结果的**统计意义不足**。此外，在很多时候设计双盲实验非常困难，而且**用户在测试环境下的行为和真实环境下的行为可能有所不同**，因而在测试环境下收集的测试指标可能在真实环境下无法重现。
5. 在线实验，一般采用AB测试的方式。
   1. AB测试：通过规则将用户分为几组，对不同的组采用不同的算法，然后对比各个组之间的评价指标。
      1. 优点：以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标。
      2. 缺点：是周期比较长，必须进行长期的实验才能得到可靠的结果。
      3. 适用场景：因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。
6. 推荐算法上线的步骤：
   1. 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。
   2. 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。
   3. 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。
7. 用户满意度。无法通过离线计算时获得。大部分需要通过用户调查或者在线实验的形式获得。
8. 预测准确度。这是最重要的推荐系统**离线**评测指标。
   1. 评分预测：预测用户对物品评分的行为。一般使用均方根误差和平均绝对误差来衡量。就是L1和L2范数。
      1. **Netflix认为RMSE加大了对预测不准的用户物品评分的惩罚（平方项的惩罚）**，因而对系统的评测更加苛刻。研究表明，如果评分系统是基于整数建立的（即用户给的评分都是整数），那么对预测结果取整会降低MAE的误差。
   2. TopN推荐：一般是给用户一个个性化的推荐列表。TopN推荐的预测准确率一般通过准确率（precision）/召回率（recall）度量。令$R(u)$是根据用户在训练集上的行为给用户作出的推荐列表，而$T(u)$是用户在测试集上的行为列表。那么，推荐结果的召回率定义为：
      $$Recall = \frac{\sum \limits_{u\in U}|R(u) \cap T(u)|}{\sum \limits_{u\in U}|T(u)|}$$
      推荐结果的准确率为：
      $$Percision = \frac{\sum \limits_{u\in U}|R(u) \cap T(u)|}{\sum \limits_{u\in U}|R(u)|}$$
   3. 覆盖率coverage：描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为$U$，推荐系统给每个用户推荐一个长度为N的物品列表$R(u)$。那么推荐系统的覆盖率可以通过下面的公式计算：$Coverage = \frac{|U_{u\in U}R(u)|}{I}$。**覆盖率是一个内容提供商会关心的指标**。两个具体的参数来衡量覆盖率：
      1. 信息熵：$H=-\sum \limits_{i=1}^n p(i)\log p(i)$，其中$p(i)$是物品$i$的流行度除以所有物品流行度之和。
      2. 基尼系数（Gini Index）：$G=\frac{1}{n-1}\sum \limits_{j=1}^n (2j-n-1)p(i)$，其中，$i_j$是按照物品流行度$p()$从小到大排序的物品列表中第$j$个物品。
   4. 多样性diversity：即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。多样性描述了推荐列表中物品两两之间的不相似性。假设$s(i, j)\in [0,1]$定义了物品$i$和$j$之间的相似度，那么用户$u$的推荐列表$R(u)$的多样性定义如下：$Diversity = 1 - \frac{\sum \limits_{i,j \in R(u), i \neq j}s(i,j)}{\frac{1}{2}|R(u)|(|R(u)|-1)}$。而推荐系统的整体多样性可以定义为所有用户推荐列表多样性的平均值：$AllDiversity = \frac{1}{|U|} \sum \limits_{u \in U}Diversity(R(U))$。
      1. 总结：即需要考虑用户的主要兴趣点，又需要考虑用户的次要兴趣点。而且需要考虑时间特性，也就是不同时间点上用户的兴趣不同。在不考虑时间的情况下，需要满足用户兴趣的分布。在考虑时间的情况下，是不同时间点上不同的兴趣分布。
      2. 这个例子举得非常清晰：假设用户喜欢动作片和动画片，且用户80%的时间在看动作片，20%的时间在看动画片。那么，可以提供4种不同的推荐列表：A列表中有10部动作片，没有动画片；B列表中有10部动画片，没有动作片；C列表中有8部动作片和2部动画片；D列表有5部动作片和5部动画片。在这个例子中，一般认为C列表是最好的，因为它具有一定的多样性，但又考虑到了用户的主要兴趣。A满足了用户的主要兴趣，但缺少多样性，D列表过于多样，没有考虑到用户的主要兴趣。B列表即没有考虑用户的主要兴趣，也没有多样性，因此是最差的。
   5. 新颖性：新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。具体评价方法：
      1. 比较简单、粗糙的方法：。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性。但是，用推荐结果的平均流行度度量新颖性比较粗略，**因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查**。
      2. 难点：**通过牺牲精度来提高多样性和新颖性是很容易的，而困难的是如何在不牺牲精度的情况下提高多样性和新颖性**。关心这两个指标的读者可以关注一下这个研讨会最终发表的论文。
      3. 参考论文：
         1. [Music Recommendation and Discovery in the Long Tail]<http://mtg.upf.edu/static/media/PhD_ocelma.pdf>
         2. [International Workshop on Novelty and Diversity in Recommender Systems]<http://ir.ii.uam.es/divers2011/>
   6. 惊喜度serendipity：
      1. 度量方法：没有。目前并没有什么公认的惊喜度指标定义方式。
      2. 一句话总结：对于将不属于用户兴趣分布范围之内的物品推荐给用户，同时用户对这个物品还非常满意，可以认为是一种惊喜。
      3. 惊喜度和新颖性的区别：符合用户兴趣分布之内，但是用户之前从来没有用过的称为新颖性。重要的是如何度量物品之间的在某个重要特征之间的差别。
      4. 参考论文
         1. Guy Shani和 Asela Gunawardana的“Evaluating Recommendation Systems”。
   7. 信任度
      1. 度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。
      2. 提高信任度的方法：
         1. 提高推荐系统的透明度，从而让用户信任推荐系统。
         2. 利用社交信息来为用户进行推荐。
      3. 总结：这个考核维度还不成熟，也不靠谱。
   8. **实时性**
      1. 新闻、微博等场景有强烈的实时性需求。
      2. 评价内容包含两个方面：
         1. 与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。
         2. 实时性的第二个方面是推荐系统需要能够将新加入系统的物品推荐给用户。这**主要考验了推荐系统处理物品冷启动的能力**。
      3. 特别说明：**冷启动不光是在系统初始化的时候需要考虑的问题，更重要的是新物品和新用户加入时需要考虑的问题**。另外，需要考虑到关联推荐（自己定义的一个名词）的问题，也就是书中举的例子，如果买了手机，那么为用户推荐充电器及手机外设相关的物品是比较合适的。
   9. 健壮性（robust，鲁棒性）
      1. 参考论文：Robustness of Recommender System。作者提供了很多攻击推荐系统算法的方法。
      2. 提高鲁棒性的方法：
         1. 设计推荐系统时尽量使用代价比较高的用户行为。
         2. 在使用数据前，进行攻击检测，从而对数据进行清理。
   10. 商业目标
   11. 总结
       1. 获取各种评测指标的途径总结表
         ||离线实验|问卷调查|在线实验|
         |---|---|---|---|
         |用户满意度|$\times$|$\surd$|$\bigcirc$|
         |预测准确度|$\surd$|$\surd$|$\times$|
         |覆盖率|$\surd$|$\surd$|$\surd$|
         |多样性|$\bigcirc$|$\surd$|$\bigcirc$|
         |新颖性|$\bigcirc$|$\surd$|$\bigcirc$|
         |惊喜度|$\times$|$\surd$|$\times$|
       2. **离线实验目标具体化**：对于可以离线优化的指标，我个人的看法是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。用一个数学公式表达，离线实验的优化目标是：
         $$
            \begin{aligned}
               & \text{最大化预测准确度} \\
               & \text{使得 覆盖率}>A \\
               & \text{多样性}>B \\
               & \text{新颖性}>C \\
               & \text{其中，A、B、C的取值应该视不同的应用而定。}
            \end{aligned}
         $$

### 评测维度

一般包含以下3个维度。比如一个推荐算法，虽然整体性能不好，但可能在某种情况下性能比较好，而增加评测维度的目的就是知道一个算法在什么情况下性能最好。

1. 用户维度
2. 物品维度
3. 时间维度

## 利用用户行为数据

实现个性化推荐的最理想情况是用户能在注册的时候主动告诉我们他喜欢什么，但这种方法有３个缺点：

1. 首先，现在的自然语言理解技术很难理解用户用来描述兴趣的自然语言；
2. 其次，用户的兴趣是不断变化的，但用户不会不停地更新兴趣描述；
3. 最后，很多时候用户并不知道自己喜欢什么，或者很难用语言描述自己喜欢什么

|概念名称|英文翻译|定义|说明|
|---|---|---|---|
|协同过滤|CF|基于用户行为分析的推荐算法是个性化推荐系统的重要算法|协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。|
|原始日志|raw log|用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志||
|会话日志|session log|会把多种原始日志按照用户行为汇总成会话日志,其中每个会话表示一次用户行为和对应的服务。||
|展示日志|impression log|在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志。||
|点击日志|click log|如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志。||
|显性反馈行为|explicit feedback|这里的主要方式就是评分和喜欢/不喜欢。|需要按照不同的目标来设计评分系统。|
|隐性反馈行为|implicit feedback|||
|无上下文信息的隐性反馈数据集||每一条行为记录仅仅包含用户ID和物品ID。Book-Crossing就是这种类型的数据集。||
|无上下文信息的显性反馈数据集||每一条记录包含用户ID、物品ID和用户对物品的评分。||
|有上下文信息的隐性反馈数据集||每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集就是这种类型的数据集。||
|有上下文信息的显性反馈数据集||每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize提供的就是这种类型的数据集。||

**上下文感觉就是是否包含时序信息**。

长尾分布是满足$f(x)=\alpha x^k$。。令$f_u(k)$为对$k$个物品产生过行为的用户数，令$f_i(k)$为被$k$个用户产生过行为的物品数。那么，$f_u(k)$和$f_i(k)$都满足长尾分布。$f_u(k)=\alpha_u k^{\beta_u}, \, f_i(k)= \alpha_i (k)^{\beta_i}$。

### 常用协同过滤算法

1. 基于邻域的方法（neighborhood-based）
2. 隐语义模型（latent factor model）
3. 基于图的随机游走算法（random walk on graph）

### Jaccard相似系数

1. 参考<https://blog.csdn.net/qq_34333481/article/details/84024513>
2. 定义：给定两个集合A,B，Jaccard系数定义为A与B交集的大小与A与B并集的大小的比值，定义为$J(A, B) = \frac{|A \cap B|}{|A \cup B|}=\frac{|A \cap B|}{|A| + |B| - |A \cap B|}$。
3. 对应的Jaccard距离用于描述两个集合之间相似的程度。Jaccard距离越大，样本相似度越低。$d_j(A, B) = 1 - J(A, B) = \frac{|A \cup B| - |A \cap B|}{|A \cup B|}$。
4. 性质$J(A, B) \in [0,1]$。
5. 具体而言：
   1. 对于集合而言，可以用样本的个数来描述$J(A,B)$，也就是交集的样本个数和并集样本个数的比值。
   2. 对于向量而言，

### 余弦相似度

1. 参考<https://blog.csdn.net/zz_dd_yy/article/details/51926305>
2. 余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫"余弦相似性"。
3. 对于两个向量$\vec{X}=\{x_1,x_2,\cdots, x_n\}, \vec{Y}= \{y_1,y_2,\cdots, y_n\}$而言，它们的余弦相似度为$\cos \theta = \frac{\sum \limits_{i=1}^{n}(x_i \times y_i)}{\sqrt{\sum \limits_{i=1}^{n}(x_i)^2} \times \sqrt{\sum \limits_{i=1}^{n}(y_i)^2}}$。
4. 举例
   $$
   \begin{aligned}
      & \vec{X}=\{1,1,2,1,1,1,0,0,0\}, \vec{Y}= \{1,1,1,0,1,1,1,1,1\} \\
      & \cos \theta = \frac{1 \times 1 + 1 \times 1 + 2 \times 1 + 1 \times 0 + 1 \times 1 + 1 \times 1 + 0 \times 1 + 0 \times 1+ 0 \times 1}{\sqrt{ 1^2 + 1^2 + 2^2 + 1^2 + 1^2 + 1^2 + 0^2 + 0^2 + 0^2} \times \sqrt{ 1^2 + 1^2 + 1^2 + 0^2 + 1^2 + 1^2 + 1^2 + 1^2 + 1^2}} \\
      & = \frac{6}{\sqrt{7} \times \sqrt{8}} \\
      & \approx 0.81 \\
   \end{aligned}
   $$

P64

## 问题

1. 覆盖率还需要好好研究一下。