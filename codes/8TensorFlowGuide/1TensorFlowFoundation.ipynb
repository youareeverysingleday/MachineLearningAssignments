{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow基本操作\n",
    "\n",
    "1. 使用的tensorflow版本是2.8.0 \n",
    "2. 参考视频<https://www.bilibili.com/video/BV1Ub4y1e7P3?p=4>\n",
    "3. **重点-参考网页**<https://zhuanlan.zhihu.com/p/377280469>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 6 * 5矩阵\n",
    "R = np.array([[4,0,1,0,5],\n",
    "     [1,2,1,3,5],\n",
    "     [4,5,3,1,0],\n",
    "     [2,3,0,2,5],\n",
    "     [5,1,4,0,0],\n",
    "     [0,3,2,4,1]])\n",
    "\n",
    "# 方阵\n",
    "R_Square = np.array([[4,0,1,0,5],\n",
    "     [1,2,1,3,5],\n",
    "     [4,5,3,1,0],\n",
    "     [2,3,0,2,5],\n",
    "     [5,1,4,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建指定大小的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 创建全零的tensor矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m =5\n",
    "K = 4\n",
    "n = 7\n",
    "# 方法一\n",
    "P = tf.zeros([m, K], dtype=float)\n",
    "Q = tf.zeros([K, n], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 创建指定大小的tensor矩阵。**推荐**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法二\n",
    "P = tf.Variable(np.random.rand(m, K), dtype=float)\n",
    "Q = tf.Variable(np.random.rand(K, n), dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将np.array转换为tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_tf = tf.convert_to_tensor(R, dtype=float)\n",
    "R_Square_tf = tf.convert_to_tensor(R_Square, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取tensor的形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([6, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取tensor矩阵指定位置的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf[1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf[1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取指定行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 2., 1., 3., 5.], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取指定列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([1., 1., 3., 0., 4., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改tensor的形状\n",
    "\n",
    "1. 若有一个维度为-1，那么tensorflow会自动推导。\n",
    "2. tf.reshape(tensor, shape, name=None)\n",
    "    1. tensor：要改变维度（形状）的张量；\n",
    "    2. shape：希望变成什么维度；\n",
    "    3. name：操作的名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "P = tf.reshape(R_tf[1, :], [1, -1])\n",
    "print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Q = tf.reshape(R_tf[:,2], [-1, 1])\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵之间乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[19.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eui = tf.matmul(tf.reshape(R_Square_tf[2, :], [1, -1]),tf.reshape(R_Square_tf[:, 3], [-1, 1])) - R_Square_tf[2,3]\n",
    "print(eui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵之间数乘\n",
    "\n",
    "1. 计算的是矩阵每个对应位置元素相乘。\n",
    "2. 需要两个矩阵形状一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 8., 15.,  0.,  2.,  0.], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(R_Square_tf[2, :], R_Square_tf[3, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数乘以矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[12.  0.  3.  0. 15.]\n",
      " [ 3.  6.  3.  9. 15.]\n",
      " [12. 15.  9.  3.  0.]\n",
      " [ 6.  9.  0.  6. 15.]\n",
      " [15.  3. 12.  0.  0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "print(a * R_Square_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor类型判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(eui, tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_tensor(eui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.is_tensor(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eui.dtype == tf.int16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eui.dtype == tf.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor的类型转换\n",
    "\n",
    "1. 参考网页<https://wenku.baidu.com/view/9a3b8439fc00bed5b9f3f90f76c66137ef064f55.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这些都是错误的，在tf 2.0之后都不支持了。\n",
    "\n",
    "# 将字符串转化为tf.float32（默认）和tf.int32\n",
    "# tf.string_to_number(string_tensor, out_type=None, name=None)\n",
    "\n",
    "# 转化为tf.float64\n",
    "# tf.to_double(eui, name='ToDouble')\n",
    "\n",
    "# 转化为tf.float32\n",
    "# tf.to_float(eui, name='ToFloat')\n",
    "\n",
    "# 转化为tf.int32\n",
    "# tf.to_int32(eui, name='ToInt32')\n",
    "\n",
    "# 转化为tf.int64\n",
    "# tf.to_int64(eui, name='ToInt64')\n",
    "\n",
    "# 转化为dtype指定的类型\n",
    "# tf.cast(x, dtype, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n",
      "tf.Tensor([0. 1. 2. 3. 4.], shape=(5,), dtype=float32)\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_0 = np.arange(5)\n",
    "print(x_0)\n",
    "x_1 = tf.convert_to_tensor(x_0, dtype=tf.int32)\n",
    "print(x_1)\n",
    "x_2 = tf.cast(x_1, dtype=tf.float32)\n",
    "print(x_2)\n",
    "x_3 = tf.cast(x_2, dtype=tf.int32)\n",
    "print(x_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵计算平方\n",
    "\n",
    "1. 计算的是每个元素的平方值\n",
    "2. tf.math还有这个类，下面应该有很多数学方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[361.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "eui_square = tf.square(eui)\n",
    "print(eui_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[16.  0.  1.  0. 25.]\n",
      " [ 1.  4.  1.  9. 25.]\n",
      " [16. 25.  9.  1.  0.]\n",
      " [ 4.  9.  0.  4. 25.]\n",
      " [25.  1. 16.  0.  0.]\n",
      " [ 0.  9.  4. 16.  1.]], shape=(6, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "R_tf_square = tf.square(R_tf)\n",
    "print(R_tf_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算tensor所有行或者所有列的和\n",
    "\n",
    "1. 使用tf.reduce_sum来完成\n",
    "2. 建议都需要填写keepdims=True参数，用于保证tensor的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 5), dtype=float32, numpy=\n",
       "array([[4., 0., 1., 0., 5.],\n",
       "       [1., 2., 1., 3., 5.],\n",
       "       [4., 5., 3., 1., 0.],\n",
       "       [2., 3., 0., 2., 5.],\n",
       "       [5., 1., 4., 0., 0.],\n",
       "       [0., 3., 2., 4., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_sum in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_sum(input_tensor, axis=None, keepdims=False, name=None)\n",
      "    Computes the sum of elements across dimensions of a tensor.\n",
      "    \n",
      "    This is the reduction operation for the elementwise `tf.math.add` op.\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
      "    reduced dimensions are retained with length 1.\n",
      "    \n",
      "    If `axis` is None, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "      >>> # x has a shape of (2, 3) (two rows and three columns):\n",
      "      >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "      >>> x.numpy()\n",
      "      array([[1, 1, 1],\n",
      "             [1, 1, 1]], dtype=int32)\n",
      "      >>> # sum all the elements\n",
      "      >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
      "      >>> tf.reduce_sum(x).numpy()\n",
      "      6\n",
      "      >>> # reduce along the first dimension\n",
      "      >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "      >>> tf.reduce_sum(x, 0).numpy()\n",
      "      array([2, 2, 2], dtype=int32)\n",
      "      >>> # reduce along the second dimension\n",
      "      >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
      "      >>> tf.reduce_sum(x, 1).numpy()\n",
      "      array([3, 3], dtype=int32)\n",
      "      >>> # keep the original dimensions\n",
      "      >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
      "      array([[3],\n",
      "             [3]], dtype=int32)\n",
      "      >>> # reduce along both dimensions\n",
      "      >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
      "      >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
      "      >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
      "      >>> # 2 + 2 + 2 = 6\n",
      "      >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
      "      6\n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "        dimensions. Must be in the range `[-rank(input_tensor),\n",
      "        rank(input_tensor)]`.\n",
      "      keepdims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor, of the same dtype as the input_tensor.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "    int64 while tensorflow returns the same dtype as the input.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10.]\n",
      " [12.]\n",
      " [13.]\n",
      " [12.]\n",
      " [10.]\n",
      " [10.]], shape=(6, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 按行求和\n",
    "row_sum = tf.reduce_sum(R_tf, 1, keepdims=True)\n",
    "print(row_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[16. 14. 11. 10. 16.]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 按列求和\n",
    "column_sum = tf.reduce_sum(R_tf, 0, keepdims=True)\n",
    "print(column_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(67.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 对所有元素求总和\n",
    "\n",
    "total_sum = tf.reduce_sum(tf.reduce_sum(R_tf, 0))\n",
    "print(total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改tensor指定位置的值\n",
    "\n",
    "1. 重点-参考网址<https://blog.csdn.net/qq_34418352/article/details/106399327>\n",
    "2. tensor本身不能直接修改指定位置的值，需要转化为Variable之后，配合assign（动词，分配的意思）一起来完成这个操作。\n",
    "3. 使用的是tf.Variable.assign和tf.Variable.assign_add来进行修改。也就是说支队tensorflow variable类型才能使用。<https://www.jianshu.com/p/efcb86940896>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改指定位置的值第一种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(6, 5) dtype=float32, numpy=\n",
      "array([[16.,  0.,  1.,  0., 25.],\n",
      "       [ 1., 99.,  1.,  9., 25.],\n",
      "       [16., 25.,  9.,  1.,  0.],\n",
      "       [ 4.,  9.,  0.,  4., 25.],\n",
      "       [25.,  1., 16.,  0.,  0.],\n",
      "       [ 0.,  9.,  4., 16.,  1.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "R_tf_square_variable = tf.Variable(R_tf_square)\n",
    "R_tf_square_variable[1, 1].assign(99)\n",
    "print(R_tf_square_variable) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改指定位置的值第二种方法\n",
    "\n",
    "1. 这种方法也太不直接了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[16.  0.  1.  0. 25.]\n",
      " [ 1. 99.  1.  9. 25.]\n",
      " [16. 25. 44.  1.  0.]\n",
      " [ 4.  9.  0.  4. 25.]\n",
      " [25.  1. 16.  0.  0.]\n",
      " [ 0.  9.  4. 16.  1.]], shape=(6, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def ModifyTensor(input_tensor, position=None, value=None):\n",
    "    input_tensor = input_tensor.numpy()\n",
    "    input_tensor[tuple(position)] = value\n",
    "    return input_tensor\n",
    "# new_tensor\n",
    "R_tf_square_variable = tf.py_function(ModifyTensor, inp=[R_tf_square_variable, [2,2], 44], \n",
    "                            Tout=R_tf_square_variable.dtype)\n",
    "print(type(R_tf_square_variable))\n",
    "print(R_tf_square_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor变量的定义及使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 定义标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(1.0)\n",
    "b = (a + 2) * 3\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 定义矩阵变量\n",
    "3. 修改特定位置的值\n",
    "4. 修改一行值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.537704  , 0.6189068 , 0.30331826, 0.04615806, 0.9390641 ],\n",
      "       [0.4411376 , 0.77692914, 0.66065925, 0.54005116, 0.8708451 ],\n",
      "       [0.8276978 , 0.05360403, 0.6741581 , 0.75516224, 0.7454265 ]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.537704  , 0.6189068 , 0.30331826, 0.04615806, 0.9390641 ],\n",
      "       [0.4411376 , 5.        , 0.66065925, 0.54005116, 0.8708451 ],\n",
      "       [0.8276978 , 0.05360403, 0.6741581 , 0.75516224, 0.7454265 ]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.537704  , 0.6189068 , 0.30331826, 0.04615806, 0.9390641 ],\n",
      "       [0.4411376 , 5.        , 0.66065925, 0.54005116, 0.8708451 ],\n",
      "       [1.        , 2.        , 3.        , 4.        , 5.        ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(np.random.rand(3, 5), dtype=float)\n",
    "print(a)\n",
    "a[1, 1].assign(5)\n",
    "print(a)\n",
    "a[2, :].assign(tf.constant([1.0, 2.0, 3.0, 4.0, 5.0]))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. tf.Variable.assign_add的使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(1.0)\n",
    "b = (a.assign_add(2)) * 3\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 循环访问tensor变量中的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.8150224 , 0.7282639 , 0.742883  , 0.27481833, 0.24528237],\n",
      "       [0.50891954, 0.59461313, 0.30716848, 0.44362485, 0.83934766],\n",
      "       [0.572105  , 0.22647381, 0.90912443, 0.9687402 , 0.01386218]],\n",
      "      dtype=float32)>\n",
      "tf.Tensor(\n",
      "[[0.7282639 ]\n",
      " [0.59461313]\n",
      " [0.22647381]], shape=(3, 1), dtype=float32)\n",
      "Display P[i, :].shape=(5,) and P[i, :]=[0.8150224  0.7282639  0.742883   0.27481833 0.24528237]\n",
      "Display P[i, :].shape=(5,) and P[i, :]=[0.50891954 0.59461313 0.30716848 0.44362485 0.83934766]\n",
      "Display P[i, :].shape=(5,) and P[i, :]=[0.572105   0.22647381 0.90912443 0.9687402  0.01386218]\n",
      "Display P[:, j].shape=(5,) and P[:, j]=[0.8150224  0.50891954 0.572105  ]\n",
      "Display P[:, j].shape=(5,) and P[:, j]=[0.7282639  0.59461313 0.22647381]\n",
      "Display P[:, j].shape=(5,) and P[:, j]=[0.742883   0.30716848 0.90912443]\n",
      "Display P[:, j].shape=(5,) and P[:, j]=[0.27481833 0.44362485 0.9687402 ]\n",
      "Display P[:, j].shape=(5,) and P[:, j]=[0.24528237 0.83934766 0.01386218]\n"
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "K = 5\n",
    "P = tf.Variable(np.random.rand(m, K), dtype=float)\n",
    "\n",
    "for i in range(m):\n",
    "    print(\"Display P[i, :].shape={} and P[i, :]={}\".format(P[i, :].shape, P[i, :]))\n",
    "\n",
    "for j in range(K):\n",
    "    print(\"Display P[:, j].shape={} and P[:, j]={}\".format(P[i, :].shape, P[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 修改指定行，不能用=来进行赋值。必须用assign来赋值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.426511   1.0461559  0.55837667 0.8844567  0.91170746], shape=(5,), dtype=float32)\n",
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.9751168 , 0.45239753, 0.22370517, 0.09391819, 0.15972255],\n",
      "       [2.426511  , 1.0461559 , 0.55837667, 0.8844567 , 0.91170746],\n",
      "       [0.7278972 , 0.66830045, 0.1793684 , 0.6468218 , 0.531055  ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "P[1,:].assign(P[1,:] + P[0,:])\n",
    "P[1,:] = P[1,:] + P[0,:]\n",
    "print(P[1,:])\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 修改指定列\n",
    "这个地方要与第9点进行比较，并没有出现将列拿出来单独计算时的问题！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.9751168 , 0.45239753, 0.22370517, 0.09391819, 0.15972255],\n",
      "       [2.426511  , 1.0461559 , 0.55837667, 0.8844567 , 0.91170746],\n",
      "       [0.7278972 , 0.66830045, 0.1793684 , 0.6468218 , 0.531055  ]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[1.4275143 , 0.45239753, 0.22370517, 0.09391819, 0.15972255],\n",
      "       [3.472667  , 1.0461559 , 0.55837667, 0.8844567 , 0.91170746],\n",
      "       [1.3961977 , 0.66830045, 0.1793684 , 0.6468218 , 0.531055  ]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(P)\n",
    "\n",
    "P[:, 0].assign(P[:, 0] + P[:, 1])\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. **读取tensor矩阵中的一列时，直接读取出来的维度不对！需要使用reshape来调整维度**。\n",
    "\n",
    "在读取一个维度的时候，读取出来的是3个标量，而不是1*3的向量！！！在做乘法的时候表现出来了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.02205932 0.3810846  0.84163105], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.02205932]\n",
      " [0.3810846 ]\n",
      " [0.84163105]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "m = 3\n",
    "n = 5\n",
    "P = tf.Variable(np.random.rand(m, n), dtype=float)\n",
    "\n",
    "# 注意两者的维度不同！！！\n",
    "print(P[:,1])\n",
    "print(tf.reshape(P[:,1], [3,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意！！ c是一个2维的矩阵，只不过维度是[1,1]。这个和直接P[1,1]有区别！！！而且这两个值不能直接进行计算！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.8540549]], shape=(1, 1), dtype=float32)\n",
      "tf.Tensor([[-0.14594507]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.matmul(tf.reshape(P[:,1], [1,m]), tf.reshape(P[:,1], [m,1]))\n",
    "print(c)\n",
    "\n",
    "d = c - tf.Variable(1.0)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意这个报错！就不能将一个二维矩阵赋值给一个标量。\n",
    "但是按一般的理解P[1,1]取出来的值也应该是一个二维矩阵，但tensorflow做了严格的区分。\n",
    "只能通过c[0,0]来转换一下再进行赋值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnimplementedError",
     "evalue": "sliced l-value shape [] does not match r-value shape [1,1]. Automatic broadcasting not yet implemented. [Op:ResourceStridedSliceAssign] name: strided_slice/_assign",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_9100/2483040857.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(val, name)\u001b[0m\n\u001b[0;32m   1242\u001b[0m           \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m           \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m           shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[0;32m   1245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m     \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_strided_slice_assign\u001b[1;34m(self, begin, end, strides, value, name, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask)\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mellipsis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m               \u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m               shrink_axis_mask=shrink_axis_mask))\n\u001b[0m\u001b[0;32m   1381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__complex__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python37\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mresource_strided_slice_assign\u001b[1;34m(ref, begin, end, strides, value, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m   8460\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8462\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8463\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8464\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python37\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: sliced l-value shape [] does not match r-value shape [1,1]. Automatic broadcasting not yet implemented. [Op:ResourceStridedSliceAssign] name: strided_slice/_assign"
     ]
    }
   ],
   "source": [
    "P[1,1].assign(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(3, 5) dtype=float32, numpy=\n",
       "array([[0.02021691, 0.02205932, 0.9237868 , 0.32626224, 0.36083788],\n",
       "       [0.69728947, 0.8540549 , 0.22294073, 0.50841606, 0.7523607 ],\n",
       "       [0.1233462 , 0.84163105, 0.33912864, 0.5408292 , 0.43469703]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[1,1].assign(c[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. tensor之间比较大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a > b\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(2.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "if a > b:\n",
    "    print(\"a > b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. tensor与数值之间比较大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\n",
      "<class 'float'>\n",
      "a > b\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(2.0)\n",
    "b = 1.0\n",
    "\n",
    "print(type(a))\n",
    "print(type(b))\n",
    "\n",
    "if a > b:\n",
    "    print(\"a > b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. tf.slice的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable(np.random.rand(3, 5), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.9060171  0.07738302 0.46185705 0.59008974 0.82741785]], shape=(1, 5), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "sr = tf.slice(a, [0,0], [1,5])\n",
    "print(sr)\n",
    "print(type(sr))\n",
    "print(sr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.9060171 ]\n",
      " [0.02471187]\n",
      " [0.6643875 ]], shape=(3, 1), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "sc = tf.slice(a, [0,0], [3,1])\n",
    "print(sc)\n",
    "print(type(sc))\n",
    "print(sc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切片了之后无法赋值！！！！！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.9060171]], shape=(1, 1), dtype=float32)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 1)\n",
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.9060171 , 0.07738302, 0.46185705, 0.59008974, 0.82741785],\n",
      "       [0.02471187, 0.98970073, 0.97137535, 0.721932  , 0.97627556],\n",
      "       [0.6643875 , 0.8575097 , 0.9728985 , 0.7265927 , 0.24499872]],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "so = tf.slice(a, [0,0], [1,1])\n",
    "print(so)\n",
    "print(type(so))\n",
    "print(so.shape)\n",
    "\n",
    "so = 44\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor可以与数值比较大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if 1999 > eui_square:\n",
    "    print(\"OK\")\n",
    "else:\n",
    "    print(\"Fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查看tensor矩阵的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method BaseResourceVariable.eval of <tf.Variable 'Variable:0' shape=(5, 4) dtype=float32, numpy=\n",
      "array([[0.18259706, 0.34361672, 0.29749665, 0.15125796],\n",
      "       [0.81373745, 0.08230656, 0.56470615, 0.9131422 ],\n",
      "       [0.5198513 , 0.40072557, 0.99874765, 0.38617522],\n",
      "       [0.60281074, 0.3949722 , 0.4758499 , 0.31637025],\n",
      "       [0.85923576, 0.49117374, 0.80321246, 0.0234599 ]], dtype=float32)>>\n"
     ]
    }
   ],
   "source": [
    "print(P.eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求向量的范数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function norm_v2 in module tensorflow.python.ops.linalg_ops:\n",
      "\n",
      "norm_v2(tensor, ord='euclidean', axis=None, keepdims=None, name=None)\n",
      "    Computes the norm of vectors, matrices, and tensors.\n",
      "    \n",
      "    This function can compute several different vector norms (the 1-norm, the\n",
      "    Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0) and\n",
      "    matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).\n",
      "    \n",
      "    Args:\n",
      "      tensor: `Tensor` of types `float32`, `float64`, `complex64`, `complex128`\n",
      "      ord: Order of the norm. Supported values are `'fro'`, `'euclidean'`,\n",
      "        `1`, `2`, `np.inf` and any positive real number yielding the corresponding\n",
      "        p-norm. Default is `'euclidean'` which is equivalent to Frobenius norm if\n",
      "        `tensor` is a matrix and equivalent to 2-norm for vectors.\n",
      "        Some restrictions apply:\n",
      "          a) The Frobenius norm `'fro'` is not defined for vectors,\n",
      "          b) If axis is a 2-tuple (matrix norm), only `'euclidean'`, '`fro'`, `1`,\n",
      "             `2`, `np.inf` are supported.\n",
      "        See the description of `axis` on how to compute norms for a batch of\n",
      "        vectors or matrices stored in a tensor.\n",
      "      axis: If `axis` is `None` (the default), the input is considered a vector\n",
      "        and a single vector norm is computed over the entire set of values in the\n",
      "        tensor, i.e. `norm(tensor, ord=ord)` is equivalent to\n",
      "        `norm(reshape(tensor, [-1]), ord=ord)`.\n",
      "        If `axis` is a Python integer, the input is considered a batch of vectors,\n",
      "        and `axis` determines the axis in `tensor` over which to compute vector\n",
      "        norms.\n",
      "        If `axis` is a 2-tuple of Python integers it is considered a batch of\n",
      "        matrices and `axis` determines the axes in `tensor` over which to compute\n",
      "        a matrix norm.\n",
      "        Negative indices are supported. Example: If you are passing a tensor that\n",
      "        can be either a matrix or a batch of matrices at runtime, pass\n",
      "        `axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are\n",
      "        computed.\n",
      "      keepdims: If True, the axis indicated in `axis` are kept with size 1.\n",
      "        Otherwise, the dimensions in `axis` are removed from the output shape.\n",
      "      name: The name of the op.\n",
      "    \n",
      "    Returns:\n",
      "      output: A `Tensor` of the same type as tensor, containing the vector or\n",
      "        matrix norms. If `keepdims` is True then the rank of output is equal to\n",
      "        the rank of `tensor`. Otherwise, if `axis` is none the output is a scalar,\n",
      "        if `axis` is an integer, the rank of `output` is one less than the rank\n",
      "        of `tensor`, if `axis` is a 2-tuple the rank of `output` is two less\n",
      "        than the rank of `tensor`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If `ord` or `axis` is invalid.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Mostly equivalent to numpy.linalg.norm.\n",
      "    Not supported: ord <= 0, 2-norm for matrices, nuclear norm.\n",
      "    Other differences:\n",
      "      a) If axis is `None`, treats the flattened `tensor` as a vector\n",
      "       regardless of rank.\n",
      "      b) Explicitly supports 'euclidean' norm as the default, including for\n",
      "       higher order tensors.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 5), dtype=float32, numpy=\n",
       "array([[4., 0., 1., 0., 5.],\n",
       "       [1., 2., 1., 3., 5.],\n",
       "       [4., 5., 3., 1., 0.],\n",
       "       [2., 3., 0., 2., 5.],\n",
       "       [5., 1., 4., 0., 0.],\n",
       "       [0., 3., 2., 4., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4. 0. 1. 0. 5.]], shape=(1, 5), dtype=float32)\n",
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.4807405, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 计算的是向量的。\n",
    "row_vector = tf.reshape(R_tf[0, :], [1, -1])\n",
    "print(row_vector)\n",
    "\n",
    "L1 = tf.norm(row_vector, ord=1)\n",
    "print(L1)\n",
    "\n",
    "L2 = tf.norm(row_vector, ord=2)\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([16. 14. 11. 10. 16.], shape=(5,), dtype=float32)\n",
      "tf.Tensor([6.4807405 6.3245554 7.141428  6.4807405 6.4807405 5.477226 ], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 计算矩阵所有行或者所有列的范数。\n",
    "\n",
    "# 按列求L1范数\n",
    "L1_matrix = tf.norm(R_tf, ord=1, axis=0)\n",
    "print(L1_matrix)\n",
    "\n",
    "# 按行求L2范数\n",
    "L2_matrix = tf.norm(R_tf, ord=2, axis=1)\n",
    "print(L2_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求矩阵的逆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function matrix_inverse in module tensorflow.python.ops.gen_linalg_ops:\n",
      "\n",
      "matrix_inverse(input, adjoint=False, name=None)\n",
      "    Computes the inverse of one or more square invertible matrices or their adjoints (conjugate transposes).\n",
      "    \n",
      "    \n",
      "    The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "    form square matrices. The output is a tensor of the same shape as the input\n",
      "    containing the inverse for all input submatrices `[..., :, :]`.\n",
      "    \n",
      "    The op uses LU decomposition with partial pivoting to compute the inverses.\n",
      "    \n",
      "    If a matrix is not invertible there is no guarantee what the op does. It\n",
      "    may detect the condition and raise an exception or it may simply return a\n",
      "    garbage result.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "        Shape is `[..., M, M]`.\n",
      "      adjoint: An optional `bool`. Defaults to `False`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.linalg.inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.8799998  -0.8399998  -0.92        1.7199999   1.12      ]\n",
      " [ 0.39999998  0.19999999  0.6000001  -0.6        -0.6       ]\n",
      " [ 0.99999976  0.99999976  0.99999994 -1.9999998  -0.99999994]\n",
      " [-1.4799998  -0.6399999  -1.3200002   2.12        1.5200001 ]\n",
      " [ 0.7039999   0.47199994  0.536      -0.9759999  -0.696     ]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.linalg.inv(R_Square_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 求矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function transpose_v2 in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "transpose_v2(a, perm=None, conjugate=False, name='transpose')\n",
      "    Transposes `a`, where `a` is a Tensor.\n",
      "    \n",
      "    Permutes the dimensions according to the value of `perm`.\n",
      "    \n",
      "    The returned tensor's dimension `i` will correspond to the input dimension\n",
      "    `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is the rank\n",
      "    of the input tensor. Hence by default, this operation performs a regular\n",
      "    matrix transpose on 2-D input Tensors.\n",
      "    \n",
      "    If conjugate is `True` and `a.dtype` is either `complex64` or `complex128`\n",
      "    then the values of `a` are conjugated and transposed.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    In `numpy` transposes are memory-efficient constant time operations as they\n",
      "    simply return a new view of the same data with adjusted `strides`.\n",
      "    \n",
      "    TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
      "    the items permuted.\n",
      "    @end_compatibility\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    >>> x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "    >>> tf.transpose(x)\n",
      "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
      "    array([[1, 4],\n",
      "           [2, 5],\n",
      "           [3, 6]], dtype=int32)>\n",
      "    \n",
      "    Equivalently, you could call `tf.transpose(x, perm=[1, 0])`.\n",
      "    \n",
      "    If `x` is complex, setting conjugate=True gives the conjugate transpose:\n",
      "    \n",
      "    >>> x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "    ...                  [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "    >>> tf.transpose(x, conjugate=True)\n",
      "    <tf.Tensor: shape=(3, 2), dtype=complex128, numpy=\n",
      "    array([[1.-1.j, 4.-4.j],\n",
      "           [2.-2.j, 5.-5.j],\n",
      "           [3.-3.j, 6.-6.j]])>\n",
      "    \n",
      "    'perm' is more useful for n-dimensional tensors where n > 2:\n",
      "    \n",
      "    >>> x = tf.constant([[[ 1,  2,  3],\n",
      "    ...                   [ 4,  5,  6]],\n",
      "    ...                  [[ 7,  8,  9],\n",
      "    ...                   [10, 11, 12]]])\n",
      "    \n",
      "    As above, simply calling `tf.transpose` will default to `perm=[2,1,0]`.\n",
      "    \n",
      "    To take the transpose of the matrices in dimension-0 (such as when you are\n",
      "    transposing matrices where 0 is the batch dimension), you would set\n",
      "    `perm=[0,2,1]`.\n",
      "    \n",
      "    >>> tf.transpose(x, perm=[0, 2, 1])\n",
      "    <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
      "    array([[[ 1,  4],\n",
      "            [ 2,  5],\n",
      "            [ 3,  6]],\n",
      "            [[ 7, 10],\n",
      "            [ 8, 11],\n",
      "            [ 9, 12]]], dtype=int32)>\n",
      "    \n",
      "    Note: This has a shorthand `linalg.matrix_transpose`):\n",
      "    \n",
      "    Args:\n",
      "      a: A `Tensor`.\n",
      "      perm: A permutation of the dimensions of `a`.  This should be a vector.\n",
      "      conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "        to tf.math.conj(tf.transpose(input)).\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A transposed `Tensor`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4. 1. 4. 2. 5. 0.]\n",
      " [0. 2. 5. 3. 1. 3.]\n",
      " [1. 1. 3. 0. 4. 2.]\n",
      " [0. 3. 1. 2. 0. 4.]\n",
      " [5. 5. 0. 5. 0. 1.]], shape=(5, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.transpose(R_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成单位矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.eye(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对矩阵求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_will_grad = tf.Variable(np.random.rand(3, 5), dtype=float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对矩阵求偏导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d94ea807e9dd88dec85d6135010093db08445b4f78f2386ac1d177de969ce657"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
