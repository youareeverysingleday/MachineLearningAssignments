{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现对简单矩阵的因子分解Matrix Factorization Machine\n",
    "\n",
    "1. 这个非常重要，是基础技术点。需要弄清楚里面的每一个知识点。\n",
    "2. 从纯数学的角度来实现这个算法。\n",
    "3. 采用Tensorflow来对矩阵进行运算。\n",
    "4. 意义：\n",
    "   1. 为了解决矩阵稀疏的问题。\n",
    "   2. 隐性空间维度k。隐性空间是不可解释的。如果k越大说明模型越精细，也就是说将物品的划分的分类越具体；k越小表明模型泛化能力越强。k的大小决定了隐性空间的表达能力。\n",
    "   3. 如果特征数量大于样本数量时会无法训练。一般情况下都需要选择比较小的k。\n",
    "   4. 将高维矩阵分解为低维矩阵的乘积。\n",
    "5. MF的几种方式\n",
    "   1. 特征值分解：特征值和特征值分解。特征值和特征向量不唯一。\n",
    "      1. 缺点：只能对方阵使用。\n",
    "   2. 奇异值分解SVD\n",
    "   3. \n",
    "6. 使用梯度下降来进行求解时，模型的复杂度是$O(kn)$。k是隐性空间维度，n是待分解矩阵维度（需要说明，在视频里面是对一个实对称矩阵进行的分解，所以维度是$n \\times n$的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "D_Square = tf.Variable(np.random.rand(3, 3), dtype=float)\n",
    "D = tf.Variable(np.random.rand(3, 5), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3, 5) dtype=float32, numpy=\n",
      "array([[0.26082656, 0.7300368 , 0.20139404, 0.6149434 , 0.8817458 ],\n",
      "       [0.4932277 , 0.3340946 , 0.5541022 , 0.5025151 , 0.04034995],\n",
      "       [0.70651567, 0.9423688 , 0.03177893, 0.60564923, 0.0193814 ]],\n",
      "      dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
      "array([[0.6457381 , 0.76257956, 0.3799022 ],\n",
      "       [0.00645747, 0.39431894, 0.89076203],\n",
      "       [0.2524235 , 0.30996695, 0.6118661 ]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(D)\n",
    "print(D_Square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function svd in module tensorflow.python.ops.linalg_ops:\n",
      "\n",
      "svd(tensor, full_matrices=False, compute_uv=True, name=None)\n",
      "    Computes the singular value decompositions of one or more matrices.\n",
      "    \n",
      "    Computes the SVD of each inner matrix in `tensor` such that\n",
      "    `tensor[..., :, :] = u[..., :, :] * diag(s[..., :, :]) *\n",
      "     transpose(conj(v[..., :, :]))`\n",
      "    \n",
      "    ```python\n",
      "    # a is a tensor.\n",
      "    # s is a tensor of singular values.\n",
      "    # u is a tensor of left singular vectors.\n",
      "    # v is a tensor of right singular vectors.\n",
      "    s, u, v = svd(a)\n",
      "    s = svd(a, compute_uv=False)\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      tensor: `Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and\n",
      "        `N`.\n",
      "      full_matrices: If true, compute full-sized `u` and `v`. If false\n",
      "        (the default), compute only the leading `P` singular vectors.\n",
      "        Ignored if `compute_uv` is `False`.\n",
      "      compute_uv: If `True` then left and right singular vectors will be\n",
      "        computed and returned in `u` and `v`, respectively. Otherwise, only the\n",
      "        singular values will be computed, which can be significantly faster.\n",
      "      name: string, optional name of the operation.\n",
      "    \n",
      "    Returns:\n",
      "      s: Singular values. Shape is `[..., P]`. The values are sorted in reverse\n",
      "        order of magnitude, so s[..., 0] is the largest value, s[..., 1] is the\n",
      "        second largest, etc.\n",
      "      u: Left singular vectors. If `full_matrices` is `False` (default) then\n",
      "        shape is `[..., M, P]`; if `full_matrices` is `True` then shape is\n",
      "        `[..., M, M]`. Not returned if `compute_uv` is `False`.\n",
      "      v: Right singular vectors. If `full_matrices` is `False` (default) then\n",
      "        shape is `[..., N, P]`. If `full_matrices` is `True` then shape is\n",
      "        `[..., N, N]`. Not returned if `compute_uv` is `False`.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Mostly equivalent to numpy.linalg.svd, except that\n",
      "      * The order of output  arguments here is `s`, `u`, `v` when `compute_uv` is\n",
      "        `True`, as opposed to `u`, `s`, `v` for numpy.linalg.svd.\n",
      "      * full_matrices is `False` by default as opposed to `True` for\n",
      "         numpy.linalg.svd.\n",
      "      * tf.linalg.svd uses the standard definition of the SVD\n",
      "        \\\\(A = U \\Sigma V^H\\\\), such that the left singular vectors of `a` are\n",
      "        the columns of `u`, while the right singular vectors of `a` are the\n",
      "        columns of `v`. On the other hand, numpy.linalg.svd returns the adjoint\n",
      "        \\\\(V^H\\\\) as the third output argument.\n",
      "    ```python\n",
      "    import tensorflow as tf\n",
      "    import numpy as np\n",
      "    s, u, v = tf.linalg.svd(a)\n",
      "    tf_a_approx = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
      "    u, s, v_adj = np.linalg.svd(a, full_matrices=False)\n",
      "    np_a_approx = np.dot(u, np.dot(np.diag(s), v_adj))\n",
      "    # tf_a_approx and np_a_approx should be numerically close.\n",
      "    ```\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.linalg.svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.         0.99999994 0.99999994], shape=(3,), dtype=float32) tf.Tensor(\n",
      "[[-0.          0.70710677  0.70710677]\n",
      " [ 1.          0.         -0.        ]\n",
      " [-0.          0.70710677 -0.70710677]], shape=(3, 3), dtype=float32) tf.Tensor(\n",
      "[[ 1.          0.          0.        ]\n",
      " [ 0.          0.70710677 -0.70710677]\n",
      " [ 0.          0.70710677  0.70710677]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "S, U, V= tf.linalg.svd(D)\n",
    "print(S, U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.00000000e+00  9.99999940e-01  1.26880515e-08]\n",
      " [ 1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -1.26880515e-08 -9.99999940e-01]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.matmul(U,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定分解的隐藏维度\n",
    "k = 3\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d94ea807e9dd88dec85d6135010093db08445b4f78f2386ac1d177de969ce657"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
