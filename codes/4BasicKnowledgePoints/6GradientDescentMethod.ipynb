{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement Gradient Descent Method\n",
    "\n",
    "1. the focus is achieving random gradient descent method.\n",
    "2. 在矩阵因式分解的过程中，为了是得目标函数求得极值，需要将其导数等于0，来找到极值点。\n",
    "3. 为了解决在矩阵分解中两个（或者多个矩阵）同时变化的情况，这里使用的是交替最小二乘法来完成梯度下降的计算。交替最小二乘法ALS的核心思想是：\n",
    "   1. 从多个变量，选定一个变量；\n",
    "   2. 其他的变量都固定住（可以初始化一个值，这个初始化值非常有技术含量，初始化值可以通过多次随机来避免陷入局部最优解的情况），\n",
    "   3. 然后对选定的变量的进行最小二乘法；\n",
    "   4. 然后将该选定的变量进行最小二乘法之后的结果固定住；\n",
    "   5. 再从余下的变量中再选一个变量；\n",
    "   6. 重复2-5步骤，直到达到目标函数的要求。\n",
    "4. 这里为什么要用梯度下降来求矩阵分解？是因为在3中需要求矩阵的逆。一般认为矩阵的逆是不好计算的。所以通过梯度下降来迭代求出矩阵的分解因子。这样就不需要目标函数的导数等于0了，只需要求偏导数乘以步长，来进行迭代即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面的方法实现过程中非常的混乱。这里按照自己的思路来实现一遍。\n",
    "1. 先对二维数据进行来进行实现。\n",
    "2. 使用tf来实现数据的存储和使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100\n",
    "data_set = []\n",
    "for i in range(num_points):\n",
    "    x = np.random.normal(0.0, 0.55)\n",
    "    # 设置一定范围的浮动\n",
    "    y = x*0.1 + 0.3 + np.random.normal(0.0,0.03)\n",
    "    data_set.append([x, y])\n",
    "\n",
    "data_np = np.array(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44349662  0.2142893 ]\n",
      " [-0.94458878  0.17762014]\n",
      " [-0.46670187  0.23429564]\n",
      " [-0.5978357   0.24168876]\n",
      " [ 0.28492544  0.32442251]\n",
      " [ 0.54698393  0.33550743]\n",
      " [-1.17225906  0.16766618]\n",
      " [-0.42356966  0.28911941]\n",
      " [ 0.46612004  0.33139847]\n",
      " [ 0.15743141  0.25745342]\n",
      " [-0.38002071  0.3078599 ]\n",
      " [ 1.30633805  0.43297175]\n",
      " [ 0.8219286   0.38577135]\n",
      " [-1.17528828  0.22798891]\n",
      " [ 1.20212014  0.4277563 ]\n",
      " [-0.24372938  0.29896514]\n",
      " [-0.56458323  0.2646708 ]\n",
      " [ 0.99227035  0.41697785]\n",
      " [-0.50897276  0.21357705]\n",
      " [ 0.14436806  0.29891922]\n",
      " [-0.30769698  0.26622549]\n",
      " [-0.08102183  0.28655903]\n",
      " [-0.90021917  0.191658  ]\n",
      " [ 0.0964733   0.26397986]\n",
      " [ 0.20792915  0.34416814]\n",
      " [-0.50169721  0.23924987]\n",
      " [-0.17671415  0.28250281]\n",
      " [ 0.15761057  0.29178577]\n",
      " [-0.45601597  0.26033395]\n",
      " [ 0.98714466  0.39840395]\n",
      " [-0.66793474  0.22272177]\n",
      " [ 0.86476856  0.35003599]\n",
      " [ 1.13679407  0.43296578]\n",
      " [-0.83404247  0.26265672]\n",
      " [-0.64042329  0.24271486]\n",
      " [-1.29120891  0.23900408]\n",
      " [ 0.19369556  0.33730708]\n",
      " [-0.80962908  0.24298146]\n",
      " [-0.13117547  0.30490696]\n",
      " [ 0.50521839  0.36210138]\n",
      " [ 0.25505677  0.25864547]\n",
      " [-0.29619593  0.27684051]\n",
      " [ 0.97646242  0.41916916]\n",
      " [-0.29292781  0.23702414]\n",
      " [-0.13175186  0.28420265]\n",
      " [ 0.0196724   0.32078904]\n",
      " [-0.63461028  0.27646296]\n",
      " [ 0.02293885  0.25083586]\n",
      " [ 0.06393938  0.30919893]\n",
      " [-1.04505155  0.21227092]\n",
      " [ 0.13623309  0.33452397]\n",
      " [-0.52260306  0.25109199]\n",
      " [ 0.74896084  0.39515927]\n",
      " [-0.75372683  0.22949264]\n",
      " [-0.23050848  0.2838431 ]\n",
      " [-0.73368062  0.18137235]\n",
      " [-0.81697774  0.2170441 ]\n",
      " [ 0.86399404  0.3807359 ]\n",
      " [ 0.17796423  0.36012627]\n",
      " [ 0.4130081   0.34635195]\n",
      " [-0.26787831  0.31343102]\n",
      " [ 0.36655514  0.36135735]\n",
      " [ 0.82571897  0.381226  ]\n",
      " [-0.47186276  0.19560379]\n",
      " [ 0.18385976  0.3344638 ]\n",
      " [-0.85197112  0.25977679]\n",
      " [ 0.28288031  0.31613772]\n",
      " [-0.4145068   0.25660075]\n",
      " [ 0.16392479  0.32392384]\n",
      " [-0.74856919  0.23197802]\n",
      " [-0.92997607  0.15291146]\n",
      " [-0.41117772  0.23773903]\n",
      " [ 0.39675285  0.32692723]\n",
      " [-0.14502744  0.26552548]\n",
      " [ 0.51538274  0.30400967]\n",
      " [ 0.39922394  0.37958288]\n",
      " [ 0.47227732  0.3260051 ]\n",
      " [ 0.17758059  0.29452169]\n",
      " [ 0.89746275  0.41170214]\n",
      " [ 0.11856784  0.39297942]\n",
      " [-0.133338    0.31620659]\n",
      " [ 0.08189893  0.29695805]\n",
      " [-0.40867799  0.28090083]\n",
      " [-0.14664411  0.27545678]\n",
      " [-0.30242844  0.30439956]\n",
      " [-0.05109155  0.33282749]\n",
      " [ 0.73148434  0.33022282]\n",
      " [-0.05381049  0.30182672]\n",
      " [-0.55932147  0.24956908]\n",
      " [-0.49385796  0.29492919]\n",
      " [ 0.46543445  0.35137063]\n",
      " [-0.70727846  0.22021998]\n",
      " [ 0.14338163  0.34018756]\n",
      " [ 0.77179488  0.41629981]\n",
      " [-0.14354457  0.26366059]\n",
      " [ 0.03314047  0.25477927]\n",
      " [ 0.32570533  0.28118606]\n",
      " [ 0.27541095  0.36537828]\n",
      " [-0.54395191  0.27335466]\n",
      " [ 0.46270108  0.37080244]]\n"
     ]
    }
   ],
   "source": [
    "# print(data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data_np[:,0], data_np[:,1], c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = tf.Variable(data_np, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考使用tensorflow求导来对线性回归拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # tf为2.0版本 python版本为3.6\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "# 定义原数据\n",
    "X_raw = np.array([2013,2014,2015,2016,2017],dtype=np.float32)\n",
    "Y_raw = np.array([12000,14000,15000,16500,17500],dtype=np.float32)\n",
    "\n",
    "# 数据归一化\n",
    "x = (X_raw - X_raw.min())/(X_raw.max() - X_raw.min())\n",
    "y = (Y_raw - Y_raw.min())/(Y_raw.max() - Y_raw.min())\n",
    "# 定义张量\n",
    "X = tf.constant(x)\n",
    "y = tf.constant(y)\n",
    "# 定义参数\n",
    "a = tf.Variable(initial_value=0.)\n",
    "b = tf.Variable(initial_value=0.)\n",
    "variables = [a,b]\n",
    "\n",
    "num_epoch = 10000 # 定义迭代次数\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3) # 定义优化器，用以后续更新参数\n",
    "for e in range(num_epoch): # 迭代多次，更新参数a与b\n",
    "    # 使用tf.GradientTape() 记录损失函数的梯度信息\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = a * X + b \n",
    "        loss = tf.reduce_sum(tf.square(y_pred - y)) # 通过预测值与实际值 求出误差\n",
    "    # Tensorflow 自动计算损失函数关于自变量（模型参数）的梯度\n",
    "    grads = tape.gradient(loss,variables) # 求损失关于参数a b的梯度\n",
    "    # Tensorflow 自动根据梯度更新参数，即利用梯度信息修改a与b，使得损失减小\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads,variables)) \n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照李宏毅课程中的步骤来完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义超参数hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习步长\n",
    "learning_rate = 0.0001\n",
    "# 循环次数\n",
    "circle_count = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先定义函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 然后对一个五维的数据进行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 没有使用正确的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = np.array([[4,0,1,0,5],\n",
    "     [1,2,1,3,5],\n",
    "     [4,5,3,1,0],\n",
    "     [2,3,0,2,5],\n",
    "     [5,1,4,0,0],\n",
    "     [0,3,2,4,1]])\n",
    "# 为0的地方并不是评分为0，而是用户并没有对该物品进行评价。没有评分的地方并不用考虑它的误差。\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"_summary_\n",
    "输入\n",
    "R 是m*n的评分矩阵\n",
    "K 隐性特征向量维度。注意这个特征维度是人为定义的。但是按道理这不应该有人为定义。\n",
    "steps/max_iter 最大迭代步长\n",
    "alpha 步长\n",
    "lamda 正则化系数\n",
    "\n",
    "输出\n",
    "分解之后的P和Q\n",
    "P 初始化用户特征矩阵m*k\n",
    "Q 初始化物品特征矩阵k*n\n",
    "\"\"\"\n",
    "\n",
    "# 对超参数进行赋值\n",
    "K=2\n",
    "max_iter = 5000 #迭代次数多意味着步长比较小。\n",
    "alpha = 0.0002\n",
    "lamda = 0.004\n",
    "\n",
    "def grad(R, K=2, max_iter= 5000, alpha=0.001, lamda= 0.002, cost_threshold = 0.0001):\n",
    "    m = len(R)\n",
    "    n = len(R[0])\n",
    "    \n",
    "    P = np.random.rand(m, K)\n",
    "    Q = np.random.rand(K, n)\n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        # 对所有的用户u和物品i做遍历。对对应的Pu和Qi向量进行梯度下降。\n",
    "        for u in range(m):\n",
    "            for i in range(n):\n",
    "                # 对于每一个大于0的评分，求出评分误差。\n",
    "                if R[u][i] > 0:\n",
    "                    eui = np.dot(P[u, :],Q[:, i]) - R[u,i]\n",
    "                    \n",
    "                    # 带入梯度下降的公式，按照梯度下降算法更新当前的Pu和Qi。也就是按照K个隐藏维度来更新。\n",
    "                    for k in range(K):\n",
    "                        # 注意这里和公式不同的地方在于求和公式。由于求和是对i在求和，而本计算是包含在\n",
    "                        # for i in range(n):当中的，就相对于每个步骤都减去了一个对于i的元素，所以不\n",
    "                        # 用再求和了。\n",
    "                        P[u][k] = P[u][k] - alpha * (2 * eui * Q[k][i] - 2 * lamda * P[u][k])\n",
    "                        # 同样的\n",
    "                        Q[k][i] = Q[k][i] - alpha * (2 * eui * P[u][k] - 2 * lamda * Q[k][i])\n",
    "                \n",
    "        # u和i遍历完成。所有特征向量都更新完成。可以计算预测评分矩阵。\n",
    "        # predictR = np.dot(P, Q)\n",
    "        # 计算当前的损失函数。\n",
    "        cost = 0\n",
    "        \n",
    "        for u in range(m):\n",
    "            for i in range(n):\n",
    "                # 在评分矩阵R中为0的不计算损失函数，原因依然是为0的评分可能是用户没有评分。\n",
    "                if R[u][i] > 0:\n",
    "                    cost += (np.dot(P[u, :],Q[:, i]) - R[u,i]) ** 2\n",
    "                    for k in range(K):\n",
    "                        cost += lamda * (P[u][k] ** 2 + Q[k][i] ** 2)\n",
    "        # 当损失函数小于某一个特定阈值时退出。\n",
    "        if cost < cost_threshold:\n",
    "            break\n",
    "    return P, Q, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin R is [[4 0 1 0 5]\n",
      " [1 2 1 3 5]\n",
      " [4 5 3 1 0]\n",
      " [2 3 0 2 5]\n",
      " [5 1 4 0 0]\n",
      " [0 3 2 4 1]], \n",
      "\n",
      " predict Matrix is [[ 3.08530702  1.92869752  2.11718031  3.54010476  5.13398751]\n",
      " [ 2.09603817  0.87096131  1.44174417  2.88328844  4.719205  ]\n",
      " [ 3.86158274  5.07022909  2.62923045  1.53899963 -1.01951784]\n",
      " [ 2.84000453  1.96195705  1.94740031  3.05549172  4.20276956]\n",
      " [ 4.67550674  1.81305316  3.21702057  6.57283231 10.89051844]\n",
      " [ 3.33665781  3.41411086  2.27933898  2.38243145  1.82918127]], \n",
      "\n",
      "  User matrix is [[ 1.61932674  0.59191702]\n",
      " [ 1.43891851  0.13441167]\n",
      " [-0.02179166  2.35952158]\n",
      " [ 1.34666796  0.65856847]\n",
      " [ 3.30977281  0.2207581 ]\n",
      " [ 0.72685412  1.44957194]], \n",
      "\n",
      " Item matrix is [[ 1.30267523  0.40421375  0.89710065  1.94118608  3.31718897]\n",
      " [ 1.64862666  2.15257094  1.12259188  0.67017878 -0.40145036]], \n",
      "\n",
      " Cost is 14.632448538433511\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "P, Q, cost = grad(R, K, max_iter, alpha, lamda)\n",
    "predictR = np.dot(P, Q)\n",
    "print(\"origin R is {}, \\n\\n predict Matrix is {}, \\n\\n  User matrix is {}, \\n\\n Item matrix is {}, \\n\\n Cost is {}\\n\\n\".format(R, predictR, P, Q, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin R is [[4 0 1 0 5]\n",
      " [1 2 1 3 5]\n",
      " [4 5 3 1 0]\n",
      " [2 3 0 2 5]\n",
      " [5 1 4 0 0]\n",
      " [0 3 2 4 1]], \n",
      "\n",
      " predict Matrix is [[3.98129334 2.88772337 1.03185416 2.2871385  5.00714545]\n",
      " [1.00423263 2.00907678 0.98400247 3.00982762 5.00561081]\n",
      " [4.02301129 4.99966975 2.99214759 0.99586013 8.17229013]\n",
      " [1.98796753 3.02288686 2.15911716 2.00039133 5.00294678]\n",
      " [5.01446274 1.00394671 3.99722158 3.87058576 1.44459909]\n",
      " [2.49623367 2.98782827 2.00730408 4.0123347  1.0034288 ]], \n",
      "\n",
      "  User matrix is [[ 0.77263191  0.39894275  0.44141781  0.83615125  1.64913806]\n",
      " [ 1.87732493  0.30978616  0.10762536  0.35761834  0.20940714]\n",
      " [ 0.76522684  1.97498457 -0.14383774  1.6699223   0.87418461]\n",
      " [ 1.08084512  1.22845156  0.21445352  0.66658305  0.17889472]\n",
      " [ 0.10747017  0.5456395   2.46119379  0.78410461  0.32887995]\n",
      " [ 0.70083521  1.35408608  1.35217766 -0.8015405   0.66165732]], \n",
      "\n",
      " Item matrix is [[-0.00741578  0.6596376   0.17590694  1.51469259  2.00592624]\n",
      " [ 0.54959653  1.66837407  0.97702877  0.18853392  1.10260378]\n",
      " [ 1.36069905 -0.18171945  1.17516206  1.53887665 -0.55154933]\n",
      " [ 1.19028518  0.18216839  0.8996725  -0.41273327  2.16174404]\n",
      " [ 1.31697296  0.99468595 -0.46377891  0.42897822  0.88127599]], \n",
      "\n",
      " Cost is 0.9973872907468129\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 通过上面的结果观察，评分矩阵和实际的评分直接误差有点大。\n",
    "# 这个时候思考可能分解的维度可能太低了，测试提高分解维度来观察结果。\n",
    "K= 5\n",
    "P, Q, cost = grad(R, K, max_iter, alpha, lamda)\n",
    "predictR = np.dot(P, Q)\n",
    "print(\"origin R is {}, \\n\\n predict Matrix is {}, \\n\\n  User matrix is {}, \\n\\n Item matrix is {}, \\n\\n Cost is {}\\n\\n\".format(R, predictR, P, Q, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tensorflow来实现特征值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "R_square = np.array([[4,0,1,0,5],\n",
    "     [1,2,1,3,5],\n",
    "     [4,5,3,1,0],\n",
    "     [2,3,0,2,5],\n",
    "     [5,1,4,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(tf.gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重新用矩阵的思维来写特征值分解。感觉以前写的有点问题。\n",
    "\n",
    "\n",
    "用tensor来实现。用tensorflow来实现完成。但是还不是用的矩阵思维。还是有问题。主要是对算法理解还有问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress is 0.0\n",
      "Progress is 1.0\n",
      "Progress is 2.0\n",
      "Progress is 3.0\n",
      "Progress is 4.0\n",
      "Progress is 5.0\n",
      "Progress is 6.0\n",
      "Progress is 7.0\n",
      "Progress is 8.0\n",
      "Progress is 9.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "K=2\n",
    "max_iter = 5000 #迭代次数多意味着步长比较小。\n",
    "alpha = 0.0002\n",
    "lamda = 0.004\n",
    "\n",
    "def GDM_Tensor(R, K=2, max_iter= 5000, alpha=0.001, lamda= 0.002, cost_threshold = 0.0001):\n",
    "    m = len(R)\n",
    "    n = len(R[0])\n",
    "\n",
    "    R_tf = tf.convert_to_tensor(R, dtype=float)\n",
    "    P = tf.Variable(np.random.rand(m, K), dtype=float)\n",
    "    Q = tf.Variable(np.random.rand(K, n), dtype=float)\n",
    "    # print(\"Display P.shape={} and  Q.shape={}\".format(P.shape, Q.shape))\n",
    "\n",
    "    for step in range(max_iter):\n",
    "        if step%100 == 0:\n",
    "            print(\"Progress is {}\".format(step/100 + 1))\n",
    "        # 按逻辑对于用户必须逐行更新，对于item必须逐列更新。\n",
    "        for u in range(m):\n",
    "            for i in range(n):\n",
    "                if R[u][i] > 0:\n",
    "                    # print(\"Display P[u, :].shape={} and  Q[:, i].shape={}\".format(P[u, :].shape, Q[:, i].shape))\n",
    "                    # eui = tf.matmul(P[u, :], Q[:, i]) - R[u,i]\n",
    "                    eui = (tf.matmul(tf.reshape(P[u, :], [1,K]), tf.reshape(Q[:, i], [K,1])) - R[u,i])[0,0]\n",
    "                    # print(eui)\n",
    "                    # print(type(eui))\n",
    "                    for k in range(K):\n",
    "                        # 注意这里和公式不同的地方在于求和公式。由于求和是对i在求和，而本计算是包含在\n",
    "                        # for i in range(n):当中的，就相对于每个步骤都减去了一个对于i的元素，所以不\n",
    "                        # 用再求和了。\n",
    "                        P[u, k].assign(P[u, k] - alpha * (2 * eui * Q[k, i] - 2 * lamda * P[u, k]))\n",
    "                        Q[k, i].assign(Q[k, i] - alpha * (2 * eui * P[u, k] - 2 * lamda * Q[k, i]))\n",
    "                        break\n",
    "                    \n",
    "        # print(\"Cycle end.\")\n",
    "        # 这个是收敛条件之一。\n",
    "        cost = tf.Variable(0.0)\n",
    "        Eui_matrix = tf.matmul(P, Q) - R_tf\n",
    "        cost = tf.reduce_sum(tf.reduce_sum(tf.square(Eui_matrix))) + lamda * (tf.reduce_sum(tf.reduce_sum(tf.square(P), 0)) + tf.reduce_sum(tf.reduce_sum(tf.square(Q), 0)))\n",
    "        \n",
    "        if cost <= cost_threshold:\n",
    "            break\n",
    "    \n",
    "    return P, Q, cost\n",
    "\n",
    "P, Q, cost = GDM_Tensor(R_square, K=2, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(5, 2) dtype=float32, numpy=\n",
      "array([[1.5650222 , 0.4134315 ],\n",
      "       [1.3195595 , 0.64713115],\n",
      "       [2.619709  , 0.37340465],\n",
      "       [1.4728941 , 0.84225214],\n",
      "       [2.181799  , 0.8092877 ]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 5) dtype=float32, numpy=\n",
      "array([[1.5793083 , 1.3907872 , 1.1425058 , 0.84974104, 3.2946165 ],\n",
      "       [0.6499688 , 0.14561683, 0.34822193, 0.11311472, 0.2997057 ]],\n",
      "      dtype=float32)>\n",
      "tf.Tensor(167.67068, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(P)\n",
    "print(Q)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用tensorflow来实现这个函数.\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# def ModifyTensor(input_tensor, position=None, value=None):\n",
    "#     input_tensor = input_tensor.numpy()\n",
    "#     input_tensor[tuple(position)] = value\n",
    "#     return input_tensor\n",
    "\n",
    "# K=2\n",
    "# max_iter = 5000 #迭代次数多意味着步长比较小。\n",
    "# alpha = 0.0002\n",
    "# lamda = 0.004\n",
    "\n",
    "# # tf.debugging.set_log_device_placement(True)\n",
    "# def grad_tf(R, K=2, max_iter= 5000, alpha=0.001, lamda= 0.002, cost_threshold = 0.0001):\n",
    "#     R_tf = tf.convert_to_tensor(R, dtype=float)\n",
    "#     m = len(R)\n",
    "#     n = len(R[0])\n",
    "    \n",
    "#     # P = np.random.rand(m, K)\n",
    "#     # Q = np.random.rand(K, n)\n",
    "#     P = tf.Variable(tf.zeros([m, K], dtype=float))\n",
    "#     Q = tf.Variable(tf.zeros([K, n], dtype=float))\n",
    "    \n",
    "#     for step in range(max_iter):\n",
    "#         # 对所有的用户u和物品i做遍历。对对应的Pu和Qi向量进行梯度下降。\n",
    "#         for u in range(m):\n",
    "#             for i in range(n):\n",
    "#                 # 对于每一个大于0的评分，求出评分误差。\n",
    "#                 if R_tf[u][i] > 0:\n",
    "#                     eui = tf.matmul(tf.reshape(P[u, :], [1, -1]),tf.reshape(Q[:, i], [-1, 1])) - R_tf[u,i]\n",
    "                    \n",
    "#                     # 带入梯度下降的公式，按照梯度下降算法更新当前的Pu和Qi。也就是按照K个隐藏维度来更新。\n",
    "#                     for k in range(K):\n",
    "#                         # 注意这里和公式不同的地方在于求和公式。由于求和是对i在求和，而本计算是包含在\n",
    "#                         # for i in range(n):当中的，就相对于每个步骤都减去了一个对于i的元素，所以不\n",
    "#                         # 用再求和了。\n",
    "#                         P = tf.py_function(ModifyTensor, \n",
    "#                                            inp=[P, [u, k], P[u][k] - alpha * (2 * eui * Q[k][i] - 2 * lamda * P[u][k])], \n",
    "#                                            Tout=P.dtype)\n",
    "#                         # 同样的\n",
    "#                         Q = tf.py_function(ModifyTensor, \n",
    "#                                            inp=[Q, [k, i], Q[k][i] - alpha * (2 * eui * P[u][k] - 2 * lamda * Q[k][i])], \n",
    "#                                            Tout=Q.dtype)\n",
    "                \n",
    "#         # u和i遍历完成。所有特征向量都更新完成。可以计算预测评分矩阵。\n",
    "#         # predictR = np.dot(P, Q)\n",
    "#         # 计算当前的损失函数。\n",
    "#         cost = 0\n",
    "        \n",
    "#         for u in range(m):\n",
    "#             for i in range(n):\n",
    "#                 # 在评分矩阵R_tf中为0的不计算损失函数，原因依然是为0的评分可能是用户没有评分。\n",
    "#                 if R_tf[u][i] > 0:\n",
    "#                     cost += (tf.matmul(tf.reshape(P[u, :], [1, -1]),tf.reshape(Q[:, i], [-1, 1])) - R_tf[u,i]) ** 2\n",
    "#                     for k in range(K):\n",
    "#                         cost += lamda * (tf.square(P[u][k]) + tf.square(Q[k][i]))\n",
    "#         # 当损失函数小于某一个特定阈值时退出。\n",
    "#         if cost < cost_threshold:\n",
    "#             break\n",
    "#     return P, Q, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_6888/2097229772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_tf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "# P, Q, cost = grad_tf(R, K=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Eig in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# R_tf = tf.convert_to_tensor(R_square, dtype=float)\n",
    "# # tensorflow进行eig必须是方阵。\n",
    "# # \n",
    "# M, N = tf.eig(R_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.5489885-1.8442735e-08j -1.7649044-1.9651887e+00j\n",
      " -1.7649044+1.9651892e+00j  2.9616973-3.0399860e-08j\n",
      " 11.019123 +6.4537744e-09j], shape=(5,), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "# print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.50880915+0.00434304j  0.28622308-0.30314255j -0.38530356+0.15924889j\n",
      "  -0.56747574+0.20958522j  0.35919613-0.00087918j]\n",
      " [ 0.20886296-0.00178275j  0.05577823-0.29754078j -0.29786214-0.05403553j\n",
      "   0.42365906-0.15646952j  0.4714589 -0.00115396j]\n",
      " [ 0.61511016-0.0052503j  -0.1284342 +0.6106717j   0.61630976+0.09786545j\n",
      "   0.6015964 -0.2221869j   0.530147  -0.0012976j ]\n",
      " [-0.5167199 +0.00441057j  0.38827828+0.04287843j -0.09845588+0.37802777j\n",
      "   0.12856518-0.04748289j  0.4572356 -0.00111915j]\n",
      " [ 0.22815934-0.00194746j -0.42346954+0.11488671j  0.25839487-0.35462296j\n",
      "  -0.00247677+0.00091478j  0.39821923-0.00097469j]], shape=(5, 5), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "# print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op Add in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# x = tf.constant([[1,2], [3,4]])\n",
    "# y = tf.add(x, 1)\n",
    "# print(y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d94ea807e9dd88dec85d6135010093db08445b4f78f2386ac1d177de969ce657"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
