{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单TF-IDF示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定义数据和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m没有使用标点符号。\n",
    "docA = \"The cat sat on my bed\"\n",
    "docB = \"The dog sat on my kness\"\n",
    "\n",
    "# 先分词。生成词袋。\n",
    "bowA = docA.split(\" \")\n",
    "bowB = docB.split(\" \")\n",
    "\n",
    "# 构建完整词库，取并集。\n",
    "wordSet = set(bowA).union(set(bowB)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 进行词数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my</th>\n",
       "      <th>sat</th>\n",
       "      <th>on</th>\n",
       "      <th>kness</th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>The</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   my  sat  on  kness  bed  cat  dog  The\n",
       "0   1    1   1      0    1    1    0    1\n",
       "1   1    1   1      1    0    0    1    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用统计字典来保存词出现的次数。\n",
    "wordDictA = dict.fromkeys(wordSet, 0)\n",
    "wordDictB = dict.fromkeys(wordSet, 0)\n",
    "\n",
    "# 遍历文档，统计词数。\n",
    "for word in bowA:\n",
    "    wordDictA[word] += 1\n",
    "for word in bowB:\n",
    "    wordDictB[word] += 1\n",
    "\n",
    "pd.DataFrame([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 计算TF\n",
    "\n",
    "$$\\text{词频TF}=\\frac{\\text{某个词在一篇文章中出现的次数}}{\\text{一篇文章的总词数}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my': 0.16666666666666666,\n",
       " 'sat': 0.16666666666666666,\n",
       " 'on': 0.16666666666666666,\n",
       " 'kness': 0.0,\n",
       " 'bed': 0.16666666666666666,\n",
       " 'cat': 0.16666666666666666,\n",
       " 'dog': 0.0,\n",
       " 'The': 0.16666666666666666}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTF(wordDict, bow):\n",
    "    # 用一个字典对象记录TF\n",
    "    tfDict = {}\n",
    "    nbowCount = len(bow)\n",
    "    \n",
    "    for word,count in wordDict.items():\n",
    "        # print(word, count,)\n",
    "        tfDict[word] = count / nbowCount\n",
    "    \n",
    "    return tfDict\n",
    "\n",
    "tfA = computeTF(wordDictA, bowA)\n",
    "tfB = computeTF(wordDictB, bowB)\n",
    "\n",
    "tfA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 计算逆文档频率\n",
    "\n",
    "$$\\text{逆文档频率IDF}=\\log_{10}\\frac{\\text{语料库的文档总数}}{\\text{包含该词的文档数}+1}$$\n",
    "1. “语料库的文档总数”是固定值。\n",
    "2. 只需要求“包含该词的文档数”即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my': 2, 'sat': 2, 'on': 2, 'kness': 1, 'bed': 1, 'cat': 1, 'dog': 1, 'The': 2}\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 1\n",
      "2 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'my': 0.0,\n",
       " 'sat': 0.0,\n",
       " 'on': 0.0,\n",
       " 'kness': 0.17609125905568124,\n",
       " 'bed': 0.17609125905568124,\n",
       " 'cat': 0.17609125905568124,\n",
       " 'dog': 0.17609125905568124,\n",
       " 'The': 0.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def computeIDF(wordDictList):\n",
    "    # 用一个字典对象来保存idf结果，每个词作为key，初始值为0。\n",
    "    idfDict = dict.fromkeys(wordDictList[0], 0)\n",
    "    N = len(wordDictList)\n",
    "    \n",
    "    for wordDict in wordDictList:\n",
    "        # 遍历字典中的每个词汇，统计Ni\n",
    "        for word,count in wordDict.items():\n",
    "            if count > 0 :\n",
    "                # 先把Ni增加1，存入到idfDict\n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    print(idfDict)\n",
    "    # 已经得到所有词汇i对应的Ni，现在更加公式把它替换为idf值。\n",
    "    for word, ni in idfDict.items():\n",
    "        idfDict[word] = math.log10((N+1)/(ni+1))\n",
    "        print(N, ni)\n",
    "    \n",
    "    return idfDict\n",
    "\n",
    "idfs = computeIDF([wordDictA, wordDictB])\n",
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 计算TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>my</th>\n",
       "      <th>sat</th>\n",
       "      <th>on</th>\n",
       "      <th>kness</th>\n",
       "      <th>bed</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>The</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    my  sat   on     kness       bed       cat       dog  The\n",
       "0  0.0  0.0  0.0  0.000000  0.029349  0.029349  0.000000  0.0\n",
       "1  0.0  0.0  0.0  0.029349  0.000000  0.000000  0.029349  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTFIDF(tf, idfs):\n",
    "    tfidf = {}\n",
    "    for word, tfval in tf.items():\n",
    "        tfidf[word] = tfval * idfs[word]\n",
    "        \n",
    "    return tfidf\n",
    "\n",
    "tfidfA = computeTFIDF(tfA, idfs)\n",
    "tfidfB = computeTFIDF(tfB, idfs)\n",
    "\n",
    "pd.DataFrame([tfidfA, tfidfB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个相对复杂的例子\n",
    "\n",
    "1. 几个文件PDF导出成txt的时候格式还都不一样。wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 对于第一个字符如果是特殊字符的行不进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipCharList = ['\\n', '\\r', '\\t', ' ', '.', ':', 'a', 'b', 'c', 'd', \n",
    "                'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', \n",
    "                'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 设置总词库\n",
    "   1. 列名是单词。\n",
    "   2. 行名是不同的文章的名称或者对应的index。\n",
    "   3. 目前是四篇paper，创建的词袋是4行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [P1, P2, P3, P4]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordBag = pd.DataFrame([[],[],[],[]])\n",
    "# 设置行名称。\n",
    "WordBag.index = pd.Series(['P1', 'P2', 'P3', 'P4'])\n",
    "WordBag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 定义将词添加入总词袋中，并且对出现的次数进行记录的函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddWordToWordBag(paperName, word):\n",
    "    # WordList = WordBag.columns.to_list()\n",
    "    if word in skipCharList:\n",
    "        return\n",
    "    if word in WordBag.columns.to_list():\n",
    "        WordBag.loc[paperName, word] += 1\n",
    "    else:\n",
    "        WordBag[word] = 0\n",
    "        WordBag.loc[paperName, word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试函数\n",
    "\n",
    "# words = ['attention', 'NaN', 'all', 'is', 'you', 'need', 'NaN', 'NaN']\n",
    "\n",
    "# for word in words:\n",
    "#     AddWordToWordBag(1, word)\n",
    "    \n",
    "# print(WordBag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 定义文本路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4个文本的读取路径。\n",
    "PaperPathList = [\"../../data/TFIDF/1.txt\", \n",
    "                 \"../../data/TFIDF/2.txt\", \n",
    "                 \"../../data/TFIDF/3.txt\", \n",
    "                 \"../../data/TFIDF/4.txt\"]\n",
    "\n",
    "# 4个文本的TFIDF保存路径。\n",
    "SaveTFIDFPathList = [\"../../data/TFIDF/P1_TFIDF.csv\",  \n",
    "                     \"../../data/TFIDF/P2_TFIDF.csv\", \n",
    "                     \"../../data/TFIDF/P3_TFIDF.csv\", \n",
    "                     \"../../data/TFIDF/P4_TFIDF.csv\"]\n",
    "\n",
    "# 词袋的保存路径。\n",
    "SaveWordBagPath = \"../../data/TFIDF/WordBag.csv\"\n",
    "\n",
    "# 最终结果的保存路径。\n",
    "SaveToExcelPath = \"../../data/TFIDF/ExcelOutput.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对第一个文档进行处理。\n",
    "\n",
    "1. 在PDF导出为txt的时候就将所有的文字分为了逐个的单词，而且每个单词占一行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    neural  collaborative  filtering  xiangnan  helizi  liao  hanwang  zhang  \\\n",
      "P1      44             41          4         1       1     1        1      8   \n",
      "P2       0              0          0         0       0     0        0      0   \n",
      "P3       0              0          0         0       0     0        0      0   \n",
      "P4       0              0          0         0       0     0        0      0   \n",
      "\n",
      "    national  university  ...  shen  luan  discrete  start  identifying  \\\n",
      "P1         4           6  ...     1     2         1      1            1   \n",
      "P2         0           0  ...     0     0         0      0            0   \n",
      "P3         0           0  ...     0     0         0      0            0   \n",
      "P4         0           0  ...     0     0         0      0            0   \n",
      "\n",
      "    naming  attributes  tang  ding  zhou  \n",
      "P1       1           1     1     1     1  \n",
      "P2       0           0     0     0     0  \n",
      "P3       0           0     0     0     0  \n",
      "P4       0           0     0     0     0  \n",
      "\n",
      "[4 rows x 1654 columns]\n"
     ]
    }
   ],
   "source": [
    "# 对第一篇论文进行处理\n",
    "\n",
    "\n",
    "# 逐行读取\n",
    "with open(PaperPathList[0]) as f1:\n",
    "    line = f1.readline()\n",
    "    line = line\n",
    "    \n",
    "    while line:\n",
    "        if line in skipCharList:\n",
    "            line = f1.readline()  #读取一行文件，包括换行符\n",
    "            line = line\n",
    "            continue\n",
    "\n",
    "        AddWordToWordBag('P1', re.sub(r'[^a-zA-Z]', '', line).casefold())\n",
    "        \n",
    "        # 读取下一行。\n",
    "        line = f1.readline()  #读取一行文件，包括换行符\n",
    "        line = line\n",
    "        # print(\"-----------\")\n",
    "        # print(Paper1WordList)\n",
    "        # print(\"-----------------------------------\")\n",
    "        \n",
    "print(WordBag)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对第二个文本进行处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    neural  collaborative  filtering  xiangnan  helizi  liao  hanwang  zhang  \\\n",
      "P1      44             41          4         1       1     1        1      8   \n",
      "P2       0              0          0         0       0     0        0      1   \n",
      "P3       0              0          0         0       0     0        0      0   \n",
      "P4       0              0          0         0       0     0        0      0   \n",
      "\n",
      "    national  university  ...  forms  constructing  tegration  exten  \\\n",
      "P1         4           6  ...      0             0          0      0   \n",
      "P2         1           2  ...      1             1          1      1   \n",
      "P3         0           0  ...      0             0          0      0   \n",
      "P4         0           0  ...      0             0          0      0   \n",
      "\n",
      "    sibility  shed  light  possibly  acknowledgments  foun  \n",
      "P1         0     0      0         0                0     0  \n",
      "P2         1     1      1         1                1     1  \n",
      "P3         0     0      0         0                0     0  \n",
      "P4         0     0      0         0                0     0  \n",
      "\n",
      "[4 rows x 2448 columns]\n"
     ]
    }
   ],
   "source": [
    "with open(PaperPathList[1]) as f2:\n",
    "    line = f2.readline()\n",
    "    line = line\n",
    "    while line:        \n",
    "        # 如果存在“|”字符，那么使用“|”对字符串进行分词。不然就用\".\"对字符串进行分词。\n",
    "        if \"|\" in line:\n",
    "            lineWords = line.split(\"|\")\n",
    "        else:\n",
    "            lineWords = line.split(\".\")\n",
    "        # print(lineWords)\n",
    "        \n",
    "        # if line in skipCharList:\n",
    "        #     line = f2.readline()  #读取一行文件，包括换行符\n",
    "        #     line = line\n",
    "        #     continue\n",
    "        \n",
    "        for word in lineWords:\n",
    "            AddWordToWordBag('P2', re.sub(r'[^a-zA-Z]', '', word).casefold())\n",
    "\n",
    "        line = f2.readline()  #读取一行文件，包括换行符\n",
    "        line = line\n",
    "        # print(\"--------------------------------------\")\n",
    "\n",
    "print(WordBag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对第三个文本进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    neural  collaborative  filtering  xiangnan  helizi  liao  hanwang  zhang  \\\n",
      "P1      44             41          4         1       1     1        1      8   \n",
      "P2       0              0          0         0       0     0        0      1   \n",
      "P3      27              0          0         0       0     0        0      3   \n",
      "P4       0              0          0         0       0     0        0      0   \n",
      "\n",
      "    national  university  ...  colors  viewed  color  \\\n",
      "P1         4           6  ...       0       0      0   \n",
      "P2         1           2  ...       0       0      0   \n",
      "P3         0           1  ...       1       1      1   \n",
      "P4         0           0  ...       0       0      0   \n",
      "\n",
      "    thelawwillneverbeperfectbutitsapplicationshouldbejustthisiswhatwearemissinginmyopinioneospad  \\\n",
      "P1                                                  0                                              \n",
      "P2                                                  0                                              \n",
      "P3                                                 12                                              \n",
      "P4                                                  0                                              \n",
      "\n",
      "    apparently  anaphora  isolated  sharp  behaviour  give  \n",
      "P1           0         0         0      0          0     0  \n",
      "P2           0         0         0      0          0     0  \n",
      "P3           1         1         1      1          1     1  \n",
      "P4           0         0         0      0          0     0  \n",
      "\n",
      "[4 rows x 3290 columns]\n"
     ]
    }
   ],
   "source": [
    "with open(PaperPathList[2]) as f3:\n",
    "    line = f3.readline()\n",
    "    line = line\n",
    "    while line: \n",
    "        # 用\" \"对字符串进行分词。\n",
    "        lineWords = line.split(\" \")\n",
    "        \n",
    "        # if line in skipCharList:\n",
    "        #     line = f3.readline()  #读取一行文件，包括换行符\n",
    "        #     line = line\n",
    "        #     continue\n",
    "            \n",
    "        # print(lineWords)\n",
    "        for word in lineWords:\n",
    "            AddWordToWordBag('P3', re.sub(r'[^a-zA-Z]', '', word).casefold())\n",
    "\n",
    "        line = f3.readline()  #读取一行文件，包括换行符\n",
    "        line = line\n",
    "        # line = line[:-1]\n",
    "        # print(\"--------------------------------------\")\n",
    "\n",
    "print(WordBag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zz = Paper3WordList.columns\n",
    "# print(type(zz))\n",
    "# print(zz.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对第四个文本进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider using pd.concat instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    neural  collaborative  filtering  xiangnan  helizi  liao  hanwang  zhang  \\\n",
      "P1      44             41          4         1       1     1        1      8   \n",
      "P2       0              0          0         0       0     0        0      1   \n",
      "P3      27              0          0         0       0     0        0      3   \n",
      "P4       2              6          5         0       0     0        0      4   \n",
      "\n",
      "    national  university  ...  locationcontentaware  nguyen  adapting  drift  \\\n",
      "P1         4           6  ...                     0       0         0      0   \n",
      "P2         1           2  ...                     0       0         0      0   \n",
      "P3         0           1  ...                     0       0         0      0   \n",
      "P4         1           2  ...                     1       1         1      1   \n",
      "\n",
      "    pp  shao  thalmann  jd  cy  sigspatial  \n",
      "P1   0     0         0   0   0           0  \n",
      "P2   0     0         0   0   0           0  \n",
      "P3   0     0         0   0   0           0  \n",
      "P4   1     1         1   1   1           1  \n",
      "\n",
      "[4 rows x 4028 columns]\n"
     ]
    }
   ],
   "source": [
    "with open(PaperPathList[3]) as f4:\n",
    "    line = f4.readline()\n",
    "    line = line\n",
    "    while line: \n",
    "        # 用\" \"对字符串进行分词。\n",
    "        lineWords = line.split(\" \")\n",
    "        \n",
    "        # if line in skipCharList:\n",
    "        #     line = f4.readline()  #读取一行文件，包括换行符\n",
    "        #     line = line\n",
    "        #     continue\n",
    "            \n",
    "        # print(lineWords)\n",
    "        for word in lineWords:\n",
    "            AddWordToWordBag('P4', re.sub(r'[^a-zA-Z]', '', word).casefold())\n",
    "\n",
    "        line = f4.readline()  #读取一行文件，包括换行符\n",
    "        line = line\n",
    "        # line = line[:-1]\n",
    "        # print(\"--------------------------------------\")\n",
    "\n",
    "print(WordBag)\n",
    "# Paper4WordList.to_csv(\"../../data/TFIDF/4t.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordBag['TotalCount'] = WordBag.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordBag['max_value']=WordBag.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordBag.to_csv(SaveWordBagPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义IFIDF存储结构。\n",
    "\n",
    "1. 需要将WordBag的列名赋值给IFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neural</th>\n",
       "      <th>collaborative</th>\n",
       "      <th>filtering</th>\n",
       "      <th>xiangnan</th>\n",
       "      <th>helizi</th>\n",
       "      <th>liao</th>\n",
       "      <th>hanwang</th>\n",
       "      <th>zhang</th>\n",
       "      <th>national</th>\n",
       "      <th>university</th>\n",
       "      <th>...</th>\n",
       "      <th>nguyen</th>\n",
       "      <th>adapting</th>\n",
       "      <th>drift</th>\n",
       "      <th>pp</th>\n",
       "      <th>shao</th>\n",
       "      <th>thalmann</th>\n",
       "      <th>jd</th>\n",
       "      <th>cy</th>\n",
       "      <th>sigspatial</th>\n",
       "      <th>TotalCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TFIDF1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDF2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDF3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TFIDF4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4029 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       neural collaborative filtering xiangnan helizi liao hanwang zhang  \\\n",
       "TFIDF1    NaN           NaN       NaN      NaN    NaN  NaN     NaN   NaN   \n",
       "TFIDF2    NaN           NaN       NaN      NaN    NaN  NaN     NaN   NaN   \n",
       "TFIDF3    NaN           NaN       NaN      NaN    NaN  NaN     NaN   NaN   \n",
       "TFIDF4    NaN           NaN       NaN      NaN    NaN  NaN     NaN   NaN   \n",
       "\n",
       "       national university  ... nguyen adapting drift   pp shao thalmann   jd  \\\n",
       "TFIDF1      NaN        NaN  ...    NaN      NaN   NaN  NaN  NaN      NaN  NaN   \n",
       "TFIDF2      NaN        NaN  ...    NaN      NaN   NaN  NaN  NaN      NaN  NaN   \n",
       "TFIDF3      NaN        NaN  ...    NaN      NaN   NaN  NaN  NaN      NaN  NaN   \n",
       "TFIDF4      NaN        NaN  ...    NaN      NaN   NaN  NaN  NaN      NaN  NaN   \n",
       "\n",
       "         cy sigspatial TotalCount  \n",
       "TFIDF1  NaN        NaN        NaN  \n",
       "TFIDF2  NaN        NaN        NaN  \n",
       "TFIDF3  NaN        NaN        NaN  \n",
       "TFIDF4  NaN        NaN        NaN  \n",
       "\n",
       "[4 rows x 4029 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WordBagColumnsNameList = WordBag.columns.to_list()\n",
    "# print(WordBagColumnsNameList.remove('TotalCount'))\n",
    "# IFIDFColumnsName =  WordBag.columns.to_list().remove('TotalCount')\n",
    "# print(IFIDFColumnsName)\n",
    "IFIDF = pd.DataFrame(index=['TFIDF1', 'TFIDF2', 'TFIDF3', 'TFIDF4'], \n",
    "                     columns=WordBag.columns.to_list())\n",
    "IFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算TF\n",
    "\n",
    "1. TF为单词出现的个数除以总的单词类别数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       neural collaborative filtering  xiangnan    helizi      liao   hanwang  \\\n",
      "TFIDF1    0.0      0.000615   0.00006  0.000036  0.000036  0.000036  0.000036   \n",
      "TFIDF2    0.0           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "TFIDF3    0.0           0.0       0.0       0.0       0.0       0.0       0.0   \n",
      "TFIDF4    0.0      0.000078  0.000065       0.0       0.0       0.0       0.0   \n",
      "\n",
      "           zhang national university  ...    nguyen  adapting     drift  \\\n",
      "TFIDF1 -0.000093      0.0   -0.00007  ...       0.0       0.0       0.0   \n",
      "TFIDF2 -0.000018      0.0  -0.000035  ...       0.0       0.0       0.0   \n",
      "TFIDF3 -0.000043      0.0  -0.000014  ...       0.0       0.0       0.0   \n",
      "TFIDF4  -0.00004      0.0   -0.00002  ...  0.000031  0.000031  0.000031   \n",
      "\n",
      "              pp      shao  thalmann        jd        cy sigspatial TotalCount  \n",
      "TFIDF1       0.0       0.0       0.0       0.0       0.0        0.0   -0.09691  \n",
      "TFIDF2       0.0       0.0       0.0       0.0       0.0        0.0   -0.09691  \n",
      "TFIDF3       0.0       0.0       0.0       0.0       0.0        0.0   -0.09691  \n",
      "TFIDF4  0.000031  0.000031  0.000031  0.000031  0.000031   0.000031   -0.09691  \n",
      "\n",
      "[4 rows x 4029 columns]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "documentCount = 4\n",
    "\n",
    "for columnName in WordBag.columns.to_list():\n",
    "    # IFIDF.loc['IDF', columnName] = math.log10(documentCount/(WordBag[WordBag[columnName]>0].shape[0] + 1))\n",
    "    IDF = math.log10(documentCount/(WordBag[WordBag[columnName]>0].shape[0] + 1))\n",
    "    IFIDF.loc['TFIDF1', columnName] = (WordBag.loc['P1', columnName] / WordBag.loc['P1', 'TotalCount']) * IDF\n",
    "    IFIDF.loc['TFIDF2', columnName] = (WordBag.loc['P2', columnName] / WordBag.loc['P2', 'TotalCount']) * IDF\n",
    "    IFIDF.loc['TFIDF3', columnName] = (WordBag.loc['P3', columnName] / WordBag.loc['P3', 'TotalCount']) * IDF\n",
    "    IFIDF.loc['TFIDF4', columnName] = (WordBag.loc['P4', columnName] / WordBag.loc['P4', 'TotalCount']) * IDF\n",
    "    \n",
    "print(IFIDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFIDF.sort_values(by='TFIDF1', ascending=False, axis=1, inplace=True)\n",
    "IFIDF.loc['TFIDF1'].T.to_csv(SaveTFIDFPathList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFIDF.sort_values(by='TFIDF2', ascending=False, axis=1, inplace=True)\n",
    "IFIDF.loc['TFIDF2'].T.to_csv(SaveTFIDFPathList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFIDF.sort_values(by='TFIDF3', ascending=False, axis=1, inplace=True)\n",
    "IFIDF.loc['TFIDF3'].T.to_csv(SaveTFIDFPathList[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFIDF.sort_values(by='TFIDF4', ascending=False, axis=1, inplace=True)\n",
    "IFIDF.loc['TFIDF4'].T.to_csv(SaveTFIDFPathList[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定量的区分专业词汇、非专业词汇和中间词汇\n",
    "\n",
    "#### 存在的问题：\n",
    "\n",
    "1. 专业词汇和非专业词汇是一个模糊的概念，界限是很难划分的。\n",
    "2. 集合可以通过集合运算来闭环，在解释性上不好说明。所以直接用了一个符合直觉的方式来近似的解决这个问题。使用一个阈值来定义是否是专业词汇的界限。这个阈值目前设定为0.00005。\n",
    "3. 在保存为excel的时候存在以下几个问题：\n",
    "   1. 保存为xls格式时需要用到库xlwt。\n",
    "   2. 保存为xlsx格式时需要用到库openpyxl。\n",
    "   3. 保存为xls格式时用office excel打开报错，那是因为使用excel之后需要使用close()函数来关闭。使用了close()之后就可以正常打开了。不过看答应输出结果还是建议使用xlsx格式为好。\n",
    "4. 参考<https://blog.csdn.net/qq_43749398/article/details/123291273>\n",
    "\n",
    "#### 定量范围划分\n",
    "\n",
    "1. 将TFIDF1、TFIDF2、TFIDF3、TFIDF4中任意一个大于0.00005的词作为专业词汇。\n",
    "2. 将TFIDF1、TFIDF2、TFIDF3、TFIDF4中均小于0的词作为非专业词汇。\n",
    "3. TFIDF1、TFIDF2、TFIDF3、TFIDF4中均等于0认为是中间词汇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TFIDF1', 'TFIDF2', 'TFIDF3', 'TFIDF4'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFIDF_T = IFIDF.T\n",
    "IFIDF_T.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF1</th>\n",
       "      <th>TFIDF2</th>\n",
       "      <th>TFIDF3</th>\n",
       "      <th>TFIDF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ge</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pois</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cyclic</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locationbased</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oneclass</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>withou</th>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemitem</th>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>endow</th>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1598 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TFIDF1    TFIDF2    TFIDF3    TFIDF4\n",
       "ge                  0.0       0.0       0.0  0.001713\n",
       "pois                0.0  0.000973       0.0   0.00097\n",
       "cyclic              0.0       0.0       0.0  0.000966\n",
       "locationbased       0.0       0.0       0.0  0.000966\n",
       "poi                 0.0  0.001267       0.0  0.000905\n",
       "...                 ...       ...       ...       ...\n",
       "oneclass       0.000072       0.0       0.0       0.0\n",
       "withou         0.000072       0.0       0.0       0.0\n",
       "normalized          0.0  0.000181  0.000018       0.0\n",
       "itemitem       0.000108       0.0       0.0       0.0\n",
       "endow          0.000108       0.0       0.0       0.0\n",
       "\n",
       "[1598 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取专业词汇\n",
    "\n",
    "ProfessionalWords = IFIDF_T.loc[(IFIDF_T['TFIDF1']>0.00005) \n",
    "                                | (IFIDF_T['TFIDF2']>0.00005) \n",
    "                                | (IFIDF_T['TFIDF3']>0.00005) \n",
    "                                | (IFIDF_T['TFIDF4']>0.00005)]\n",
    "ProfessionalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF1</th>\n",
       "      <th>TFIDF2</th>\n",
       "      <th>TFIDF3</th>\n",
       "      <th>TFIDF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>temporal</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summarized</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experimental</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dation</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>additional</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typical</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>applying</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>272 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TFIDF1 TFIDF2 TFIDF3 TFIDF4\n",
       "temporal        0.0    0.0    0.0    0.0\n",
       "summarized      0.0    0.0    0.0    0.0\n",
       "experimental    0.0    0.0    0.0    0.0\n",
       "helpful         0.0    0.0    0.0    0.0\n",
       "dation          0.0    0.0    0.0    0.0\n",
       "...             ...    ...    ...    ...\n",
       "additional      0.0    0.0    0.0    0.0\n",
       "typical         0.0    0.0    0.0    0.0\n",
       "applying        0.0    0.0    0.0    0.0\n",
       "available       0.0    0.0    0.0    0.0\n",
       "neural          0.0    0.0    0.0    0.0\n",
       "\n",
       "[272 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取中间词汇\n",
    "\n",
    "MiddleWords = IFIDF_T.loc[(IFIDF_T['TFIDF1']==0) \n",
    "                                & (IFIDF_T['TFIDF2']==0) \n",
    "                                & (IFIDF_T['TFIDF3']==0) \n",
    "                                & (IFIDF_T['TFIDF4']==0)]\n",
    "MiddleWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TFIDF1</th>\n",
       "      <th>TFIDF2</th>\n",
       "      <th>TFIDF3</th>\n",
       "      <th>TFIDF4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>become</th>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuning</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>describe</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>designed</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluated</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>-0.002829</td>\n",
       "      <td>-0.00179</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>-0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.002852</td>\n",
       "      <td>-0.002545</td>\n",
       "      <td>-0.002532</td>\n",
       "      <td>-0.002707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.005215</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.004703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>-0.008207</td>\n",
       "      <td>-0.021783</td>\n",
       "      <td>-0.02538</td>\n",
       "      <td>-0.016925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalCount</th>\n",
       "      <td>-0.09691</td>\n",
       "      <td>-0.09691</td>\n",
       "      <td>-0.09691</td>\n",
       "      <td>-0.09691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              TFIDF1    TFIDF2    TFIDF3    TFIDF4\n",
       "become     -0.000023 -0.000035 -0.000014  -0.00001\n",
       "tuning     -0.000012 -0.000035 -0.000014  -0.00001\n",
       "describe   -0.000012 -0.000035 -0.000014  -0.00001\n",
       "designed   -0.000012 -0.000018 -0.000028  -0.00001\n",
       "evaluated  -0.000012 -0.000035 -0.000014  -0.00001\n",
       "...              ...       ...       ...       ...\n",
       "and        -0.002829  -0.00179 -0.002504 -0.002647\n",
       "of         -0.002852 -0.002545 -0.002532 -0.002707\n",
       "the        -0.005215 -0.005459 -0.004567 -0.004703\n",
       "           -0.008207 -0.021783  -0.02538 -0.016925\n",
       "TotalCount  -0.09691  -0.09691  -0.09691  -0.09691\n",
       "\n",
       "[198 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取非专业词汇\n",
    "\n",
    "NonprofessionalWords = IFIDF_T.loc[(IFIDF_T['TFIDF1']<0) \n",
    "                                & (IFIDF_T['TFIDF2']<0) \n",
    "                                & (IFIDF_T['TFIDF3']<0) \n",
    "                                & (IFIDF_T['TFIDF4']<0)]\n",
    "NonprofessionalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这些词汇组合成一个表格输出\n",
    "\n",
    "ExcelOutput = pd.ExcelWriter(SaveToExcelPath)\n",
    "pd.DataFrame(ProfessionalWords.index.T).to_excel(ExcelOutput, sheet_name=\"ProfessionalWords\")\n",
    "pd.DataFrame(NonprofessionalWords.index.T).to_excel(ExcelOutput, sheet_name=\"NonprofessionalWords\")\n",
    "pd.DataFrame(MiddleWords.index.T).to_excel(ExcelOutput, sheet_name=\"MiddleWords\")\n",
    "ExcelOutput.save()\n",
    "ExcelOutput.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf831573a0ff294614842876d2763885d6da16fb80bd95fae4076843946dd1d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
